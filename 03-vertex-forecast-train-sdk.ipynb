{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841bd2d5-1be0-4f59-9dd1-09e089cbc3fa",
   "metadata": {},
   "source": [
    "# Vertex Forecast - training with SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15673d55-b46c-4c9d-acca-81a94f7bcc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "REGION: us-central1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "REGION = 'us-central1'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"REGION: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d25882-7944-45b9-9136-0438367e8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as vertex_ai\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ec7706-dece-4598-87c4-6e732e0302fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously defined\n",
    "BQ_DATASET=\"m5_us\"\n",
    "BQ_TABLE=\"sdk_train\"\n",
    "BQ_TABLE_PLAN=\"sdk_plan\"\n",
    "\n",
    "# new vars\n",
    "EXPERIMENT=\"m5_nb3\"\n",
    "VERSION=\"v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d3fcb-fe98-4179-b870-18758387548f",
   "metadata": {},
   "source": [
    "## Create Vertex Managed Dataset \n",
    "* link to BigQuery Table\n",
    "\n",
    "Reference for [`aiplatform.TimeSeriesDataset.create()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.TimeSeriesDataset.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81f6a4a-687d-4f37-9fc9-23b0f36df160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TimeSeriesDataset\n",
      "Create TimeSeriesDataset backing LRO: projects/934903580331/locations/us-central1/datasets/462153324456574976/operations/658077294274805760\n",
      "TimeSeriesDataset created. Resource name: projects/934903580331/locations/us-central1/datasets/462153324456574976\n",
      "To use this TimeSeriesDataset in another session:\n",
      "ds = aiplatform.TimeSeriesDataset('projects/934903580331/locations/us-central1/datasets/462153324456574976')\n"
     ]
    }
   ],
   "source": [
    "dataset = vertex_ai.TimeSeriesDataset.create(\n",
    "    display_name = f'{EXPERIMENT}_{VERSION}', \n",
    "    bq_source = f'bq://{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_prepped',\n",
    "    labels = {'experiment':f'{EXPERIMENT}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d9675-12ec-451f-8aa1-872e3d37698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = vertex_ai.TimeSeriesDataset('projects/715288179162/locations/us-central1/datasets/462153324456574976')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47329df6-9488-4e6a-8c1f-21089ef9a557",
   "metadata": {},
   "source": [
    "## Train Forecasting Model with AutoML\n",
    "\n",
    "Reference for [`aiplatform.AutoMLForecastingTrainingJob`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.AutoMLForecastingTrainingJob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e35927f-8a53-4eb9-9094-4957728bddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "985efc39-76ed-44f8-bf0e-ae0f5be59ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_name_1',\n",
       " 'year',\n",
       " 'event_type_1',\n",
       " 'month',\n",
       " 'dept_id',\n",
       " 'sell_price',\n",
       " 'event_type_2',\n",
       " 'wday',\n",
       " 'state_id',\n",
       " 'snap_WI',\n",
       " 'snap_CA',\n",
       " 'snap_TX',\n",
       " 'product_id',\n",
       " 'date',\n",
       " 'event_name_2',\n",
       " 'location_id',\n",
       " 'weekday',\n",
       " 'cat_id']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVAILABLE_AT_FORECAST_COLS = list(set(dataset.column_names) - set(['splits','timeseries_id','gross_quantity']))\n",
    "AVAILABLE_AT_FORECAST_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e61707f1-edac-4fa3-bede-ac30d5f92e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event_name_1': 'auto',\n",
       " 'year': 'auto',\n",
       " 'event_type_1': 'auto',\n",
       " 'month': 'auto',\n",
       " 'dept_id': 'auto',\n",
       " 'sell_price': 'auto',\n",
       " 'event_type_2': 'auto',\n",
       " 'wday': 'auto',\n",
       " 'state_id': 'auto',\n",
       " 'snap_WI': 'auto',\n",
       " 'snap_CA': 'auto',\n",
       " 'snap_TX': 'auto',\n",
       " 'gross_quantity': 'auto',\n",
       " 'product_id': 'auto',\n",
       " 'date': 'auto',\n",
       " 'event_name_2': 'auto',\n",
       " 'location_id': 'auto',\n",
       " 'weekday': 'auto',\n",
       " 'cat_id': 'auto'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_specs = list(set(dataset.column_names) - set(['splits','timeseries_id']))\n",
    "column_specs = dict.fromkeys(column_specs, 'auto')\n",
    "column_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce50b7c-dfff-4c0e-a16e-6e2db335dc83",
   "metadata": {},
   "source": [
    "optimization_objective\n",
    "* \"minimize-rmse\" (default) - Minimize root-mean-squared error (RMSE).\n",
    "* \"minimize-mae\" - Minimize mean-absolute error (MAE).\n",
    "* \"minimize-rmsle\" - Minimize root-mean-squared log error (RMSLE).\n",
    "* \"minimize-rmspe\" - Minimize root-mean-squared percentage error (RMSPE).\n",
    "* \"minimize-wape-mae\" - Minimize the combination of weighted absolute percentage error (WAPE) and mean-absolute-error (MAE).\n",
    "* \"minimize-quantile-loss\" - Minimize the quantile loss at the defined quantiles. (Set this objective to build quantile forecasts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3cd6d-be80-4f43-adc7-822086d7598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE\n",
    "FORECAST_GRANULARITY = 'DAY'\n",
    "FORECAST_HORIZON = 14\n",
    "CONTEXT_WINDOW=14\n",
    "forecast_test_length = 14\n",
    "forecast_val_length = 14\n",
    "\n",
    "TARGET_COLUMN = 'gross_quantity'\n",
    "TIME_COLUMN = 'date'\n",
    "SERIES_COLUMN = 'timeseries_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "003122b6-1e37-4834-86f4-30946c7f1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_job = vertex_ai.AutoMLForecastingTrainingJob(\n",
    "    display_name = f'{EXPERIMENT}_{VERSION}_training',\n",
    "    optimization_objective = \"minimize-rmse\",\n",
    "    column_specs = column_specs,\n",
    "    labels = {'experiment':f'{EXPERIMENT}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81823ad5-6d87-4508-b6dd-b3d1095bf84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6795228562577162240?project=934903580331\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/6795228562577162240 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "forecast = forecast_job.run(\n",
    "    dataset = dataset,\n",
    "    target_column = TARGET_COLUMN,\n",
    "    time_column = TIME_COLUMN,\n",
    "    time_series_identifier_column = SERIES_COLUMN,\n",
    "    unavailable_at_forecast_columns = [TARGET_COLUMN,],\n",
    "    available_at_forecast_columns = AVAILABLE_AT_FORECAST_COLS,\n",
    "    forecast_horizon = FORECAST_HORIZON,\n",
    "    data_granularity_unit = FORECAST_GRANULARITY.lower(),\n",
    "    data_granularity_count = 1,\n",
    "    predefined_split_column_name = \"splits\",\n",
    "    context_window = CONTEXT_WINDOW,\n",
    "    export_evaluated_data_items = True,\n",
    "    export_evaluated_data_items_bigquery_destination_uri = f\"bq://{PROJECT_ID}:{BQ_DATASET}:{BQ_TABLE}_automl\",\n",
    "    validation_options = \"fail-pipeline\",\n",
    "    budget_milli_node_hours = 1000,\n",
    "    model_display_name = f\"{EXPERIMENT}_{BQ_TABLE}_{VERSION}\",\n",
    "    model_labels = {'experiment':f'{EXPERIMENT}'},\n",
    "    holiday_regions = ['GLOBAL', 'NA', 'US'],\n",
    "    sync = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad862a1b-bb14-4bfe-a0c4-a9c1856202b6",
   "metadata": {},
   "source": [
    "## Using The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e014c-561b-4f38-a752-30894b914b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    RAW AS (\n",
    "        SELECT DATE({TIME_COLUMN}) as {TIME_COLUMN}, DATE(predicted_on_date) as predicted_on_date, CAST({TARGET_COLUMN} as INT64) AS {TARGET_COLUMN}, splits, {SERIES_COLUMN}, predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "        FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_automl`\n",
    "    ),\n",
    "    LEAD AS (\n",
    "        SELECT *, DATE_DIFF({TIME_COLUMN}, predicted_on_date, {forecast_granularity}) as prediction_lead_days\n",
    "        FROM RAW\n",
    "    ),\n",
    "    LEFTSIDE AS (\n",
    "        SELECT {SERIES_COLUMN}, {TIME_COLUMN}, min(prediction_lead_days) as prediction_lead_days\n",
    "        FROM LEAD\n",
    "        GROUP BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    )\n",
    "SELECT *\n",
    "FROM LEFTSIDE\n",
    "LEFT OUTER JOIN LEAD\n",
    "USING ({SERIES_COLUMN}, {TIME_COLUMN}, prediction_lead_days)\n",
    "\"\"\"\n",
    "autoML = bigquery.query(query = query).to_dataframe()\n",
    "autoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114d9f7-580c-44fb-b2c8-34bccb95f975",
   "metadata": {},
   "source": [
    "### Review Custom Metrics with SQL\n",
    "\n",
    "Some common metrics for evaluating forecasting effectiveness are \n",
    "- MAPE, or Mean Absolute Percentage Error\n",
    "    - $\\textrm{MAPE} = \\frac{1}{n}\\sum{\\frac{\\mid(actual - forecast)\\mid}{actual}}$\n",
    "- MAE, or Mean Absolute Error\n",
    "     - $\\textrm{MAE} = \\frac{1}{n}\\sum{\\mid(actual - forecast)\\mid}$\n",
    "- MAE divided by average demand so it yields a % like MAPE\n",
    "    - $\\textrm{pMAE} = \\frac{\\sum{\\mid(actual - forecast)\\mid}}{\\sum{actual}}$\n",
    "- MSE, or Mean Squared Error\n",
    "    - $\\textrm{MSE} = \\frac{1}{n}\\sum{(actual-forecast)^2}$\n",
    "- RMSE, or Root Mean Squared Error\n",
    "    - $\\textrm{RMSE} = \\sqrt{\\frac{1}{n}\\sum{(actual-forecast)^2}}$\n",
    "- RMSE divided by average demand so it yeilds a % like MAPE\n",
    "    - $\\textrm{pRMSE} = \\frac{\\sqrt{\\frac{1}{n}\\sum{(actual-forecast)^2}}}{\\frac{1}{n}\\sum{actual}}$\n",
    "\n",
    "It can be helpful to explicity caculate these to make comparison between datasets and models fair.  This section demonstration these calculation with SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1847d0-02ad-4e9f-8947-a8d1b36bbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    FORECASTS AS (\n",
    "        SELECT DATE({TIME_COLUMN}) as {TIME_COLUMN}, \n",
    "            DATE(predicted_on_date) as predicted_on_date, \n",
    "            CAST({TARGET_COLUMN} as INT64) AS {TARGET_COLUMN}, \n",
    "            splits,\n",
    "            {SERIES_COLUMN}, \n",
    "            predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "        FROM `{PROJECT_ID}.{DATANAME}.{NOTEBOOK}_automl`\n",
    "    ),\n",
    "    LEAD_DAYS AS (\n",
    "        SELECT *, DATE_DIFF({TIME_COLUMN}, predicted_on_date, {FORECAST_GRANULARITY}) as prediction_lead_days\n",
    "        FROM FORECASTS\n",
    "    ),\n",
    "    LATEST AS (\n",
    "        SELECT {SERIES_COLUMN}, {TIME_COLUMN}, min(prediction_lead_days) as prediction_lead_days\n",
    "        FROM LEAD_DAYS\n",
    "        GROUP BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    ),\n",
    "    DIFFS AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            'forecast' as time_series_type,\n",
    "            predicted_{TARGET_COLUMN} as forecast_value,\n",
    "            {TARGET_COLUMN} as actual_value,\n",
    "            ({TARGET_COLUMN} - predicted_{TARGET_COLUMN}) as diff\n",
    "        FROM LATEST\n",
    "        LEFT OUTER JOIN LEAD_DAYS\n",
    "        USING ({SERIES_COLUMN}, {TIME_COLUMN}, prediction_lead_days)    \n",
    "    )\n",
    "SELECT {SERIES_COLUMN}, time_series_type, \n",
    "    AVG(ABS(diff)/actual_value) as MAPE,\n",
    "    AVG(ABS(diff)) as MAE,\n",
    "    SUM(ABS(diff))/SUM(actual_value) as pMAE,\n",
    "    AVG(POW(diff, 2)) as MSE,\n",
    "    SQRT(AVG(POW(diff, 2))) as RMSE,\n",
    "    SQRT(AVG(POW(diff, 2)))/AVG(actual_value) as pRMSE\n",
    "FROM DIFFS\n",
    "GROUP BY {SERIES_COLUMN}, time_series_type\n",
    "ORDER BY {SERIES_COLUMN}, time_series_type    \n",
    "\"\"\"\n",
    "customMetrics = bigquery.query(query = query).to_dataframe()\n",
    "customMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a2a3e-9967-430d-acc1-ad17224bfb4d",
   "metadata": {},
   "source": [
    "Overall Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0784de-9c1e-4bf7-86ec-1d4cfdefaadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    FORECASTS AS (\n",
    "        SELECT \n",
    "            DATE({TIME_COLUMN}) as {TIME_COLUMN}, \n",
    "            DATE(predicted_on_date) as predicted_on_date, \n",
    "            CAST({TARGET_COLUMN} as INT64) AS {TARGET_COLUMN}, \n",
    "            splits, \n",
    "            {SERIES_COLUMN}, \n",
    "            predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "        FROM `{PROJECT_ID}.{DATANAME}.{NOTEBOOK}_automl`\n",
    "    ),\n",
    "    LEAD_DAYS AS (\n",
    "        SELECT *, DATE_DIFF({TIME_COLUMN}, predicted_on_date, {FORECAST_GRANULARITY}) as prediction_lead_days\n",
    "        FROM FORECASTS\n",
    "    ),\n",
    "    LATEST AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            min(prediction_lead_days) as prediction_lead_days\n",
    "        FROM LEAD_DAYS\n",
    "        GROUP BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    ),\n",
    "    DIFFS AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            'forecast' as time_series_type,\n",
    "            predicted_{TARGET_COLUMN} as forecast_value,\n",
    "            {TARGET_COLUMN} as actual_value,\n",
    "            ({TARGET_COLUMN} - predicted_{TARGET_COLUMN}) as diff\n",
    "        FROM LATEST\n",
    "        LEFT OUTER JOIN LEAD_DAYS\n",
    "        USING ({SERIES_COLUMN}, {TIME_COLUMN}, prediction_lead_days)    \n",
    "    )\n",
    "SELECT time_series_type, \n",
    "    AVG(ABS(diff)/actual_value) as MAPE,\n",
    "    AVG(ABS(diff)) as MAE,\n",
    "    SUM(ABS(diff))/SUM(actual_value) as pMAE,\n",
    "    AVG(POW(diff, 2)) as MSE,\n",
    "    SQRT(AVG(POW(diff, 2))) as RMSE,\n",
    "    SQRT(AVG(POW(diff, 2)))/AVG(actual_value) as pRMSE\n",
    "FROM DIFFS\n",
    "GROUP BY time_series_type\n",
    "ORDER BY time_series_type    \n",
    "\"\"\"\n",
    "customMetricsOverall = bigquery.query(query = query).to_dataframe()\n",
    "customMetricsOverall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1366da1-29c3-4ad0-9376-c83b65bba9ac",
   "metadata": {},
   "source": [
    "## Get Forecasted Values for Future Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cde221-e9d6-4ab0-901a-25315be99bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f0428-830c-432f-a1b0-4239620a3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOMIZE\n",
    "FORECAST_GRANULARITY = 'DAY'\n",
    "FORECAST_HORIZON = 14\n",
    "CONTEXT_WINDOW=14\n",
    "forecast_test_length = 14\n",
    "forecast_val_length = 14\n",
    "\n",
    "TARGET_COLUMN = 'gross_quantity'\n",
    "TIME_COLUMN = 'date'\n",
    "SERIES_COLUMN = 'timeseries_id'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
