{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841bd2d5-1be0-4f59-9dd1-09e089cbc3fa",
   "metadata": {},
   "source": [
    "# Vertex Forecast - training with SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15673d55-b46c-4c9d-acca-81a94f7bcc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "REGION: us-central1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "BQ_LOCATION='US'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"REGION: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d25882-7944-45b9-9136-0438367e8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as vertex_ai\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16fb9237-5437-4c07-9fee-9acdff677006",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client(\n",
    "    project=PROJECT_ID, \n",
    "    location=BQ_LOCATION\n",
    ")\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ec7706-dece-4598-87c4-6e732e0302fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously defined\n",
    "BQ_DATASET=\"m5_us\"\n",
    "BQ_TABLE=\"sdk_train\"\n",
    "BQ_TABLE_PLAN=\"sdk_plan\"\n",
    "\n",
    "# new vars\n",
    "EXPERIMENT=\"m5_nb3\"\n",
    "VERSION=\"v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d3fcb-fe98-4179-b870-18758387548f",
   "metadata": {},
   "source": [
    "## Create Vertex Managed Dataset \n",
    "* link to BigQuery Table\n",
    "\n",
    "Reference for [`aiplatform.TimeSeriesDataset.create()`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.TimeSeriesDataset.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81f6a4a-687d-4f37-9fc9-23b0f36df160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TimeSeriesDataset\n",
      "Create TimeSeriesDataset backing LRO: projects/934903580331/locations/us-central1/datasets/462153324456574976/operations/658077294274805760\n",
      "TimeSeriesDataset created. Resource name: projects/934903580331/locations/us-central1/datasets/462153324456574976\n",
      "To use this TimeSeriesDataset in another session:\n",
      "ds = aiplatform.TimeSeriesDataset('projects/934903580331/locations/us-central1/datasets/462153324456574976')\n"
     ]
    }
   ],
   "source": [
    "dataset = vertex_ai.TimeSeriesDataset.create(\n",
    "    display_name = f'{EXPERIMENT}_{VERSION}', \n",
    "    bq_source = f'bq://{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_prepped',\n",
    "    labels = {'experiment':f'{EXPERIMENT}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d9675-12ec-451f-8aa1-872e3d37698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = vertex_ai.TimeSeriesDataset('projects/715288179162/locations/us-central1/datasets/462153324456574976')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47329df6-9488-4e6a-8c1f-21089ef9a557",
   "metadata": {},
   "source": [
    "# Train Forecasting Model with AutoML\n",
    "\n",
    "Reference for [`aiplatform.AutoMLForecastingTrainingJob`](https://googleapis.dev/python/aiplatform/latest/aiplatform.html#google.cloud.aiplatform.AutoMLForecastingTrainingJob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9116fd5-edb0-4184-b786-a1358d7c6fb9",
   "metadata": {},
   "source": [
    "## train job config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fe765-15d6-40a5-b67a-b5db965948ef",
   "metadata": {},
   "source": [
    "### column specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e35927f-8a53-4eb9-9094-4957728bddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_name_1',\n",
       " 'year',\n",
       " 'month',\n",
       " 'dept_id',\n",
       " 'wday',\n",
       " 'snap_CA',\n",
       " 'gross_quantity',\n",
       " 'product_id',\n",
       " 'date',\n",
       " 'event_name_2',\n",
       " 'timeseries_id',\n",
       " 'splits',\n",
       " 'cat_id',\n",
       " 'event_type_1',\n",
       " 'sell_price',\n",
       " 'event_type_2',\n",
       " 'state_id',\n",
       " 'snap_WI',\n",
       " 'snap_TX',\n",
       " 'location_id',\n",
       " 'weekday']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49cb86-6779-4300-9358-bdc0e71e2b96",
   "metadata": {},
   "source": [
    "### define target, time, and ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62cd18ea-29eb-48b3-b24d-0154c3069613",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'gross_quantity'\n",
    "TIME_COLUMN = 'date'\n",
    "SERIES_COLUMN = 'timeseries_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d52733-6f81-42af-add5-0c49d8f4f00f",
   "metadata": {},
   "source": [
    "### features which will be available at forecast (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "985efc39-76ed-44f8-bf0e-ae0f5be59ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_name_1',\n",
       " 'year',\n",
       " 'event_type_1',\n",
       " 'month',\n",
       " 'dept_id',\n",
       " 'event_type_2',\n",
       " 'wday',\n",
       " 'state_id',\n",
       " 'snap_WI',\n",
       " 'snap_CA',\n",
       " 'snap_TX',\n",
       " 'product_id',\n",
       " 'date',\n",
       " 'event_name_2',\n",
       " 'location_id',\n",
       " 'weekday',\n",
       " 'cat_id']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column_specs = list(set(dataset.column_names) - set(['splits','timeseries_id']))\n",
    "# column_specs = dict.fromkeys(column_specs, 'auto')\n",
    "\n",
    "AVAILABLE_AT_FORECAST_COLS = list(set(dataset.column_names) - set(['splits','timeseries_id','gross_quantity','sell_price']))\n",
    "AVAILABLE_AT_FORECAST_COLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f83cc43-6ed1-4092-ae0e-3fd04191e022",
   "metadata": {},
   "source": [
    "### features which will be unavailable at forecast (inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3ee1323-be0f-4552-b39b-cf9683d52677",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNAVAILABLE_AT_FORECAST_COLS=[\n",
    "    TARGET_COLUMN,\n",
    "    'sell_price'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39af700-9811-4db0-9083-2a8018789aaa",
   "metadata": {},
   "source": [
    "Create a dictionary containing all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7471c5d-6a7a-4316-95d7-dc7d048784be",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_TRANSFORMS = {\n",
    "    TIME_COLUMN:\"timestamp\",\n",
    "    TARGET_COLUMN:\"numeric\",\n",
    "    \"product_id\":\"categorical\",\n",
    "    \"location_id\":\"categorical\",\n",
    "    \"weekday\":\"categorical\",\n",
    "    \"event_name_1\":\"categorical\",\n",
    "    \"year\":\"categorical\",\n",
    "    \"event_type_1\":\"categorical\",\n",
    "    \"month\":\"categorical\",\n",
    "    \"dept_id\":\"categorical\",\n",
    "    \"event_type_2\":\"categorical\",\n",
    "    \"wday\":\"categorical\",\n",
    "    \"state_id\":\"categorical\",\n",
    "    \"snap_WI\":\"categorical\",\n",
    "    \"snap_CA\":\"categorical\",\n",
    "    \"snap_TX\":\"categorical\",\n",
    "    \"event_name_2\":\"categorical\",\n",
    "    \"cat_id\":\"categorical\",\n",
    "    \"sell_price\":\"numeric\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce50b7c-dfff-4c0e-a16e-6e2db335dc83",
   "metadata": {},
   "source": [
    "### model config\n",
    "\n",
    "**optimization_objective:**\n",
    "* \"minimize-rmse\" (default) - Minimize root-mean-squared error (RMSE).\n",
    "* \"minimize-mae\" - Minimize mean-absolute error (MAE).\n",
    "* \"minimize-rmsle\" - Minimize root-mean-squared log error (RMSLE).\n",
    "* \"minimize-rmspe\" - Minimize root-mean-squared percentage error (RMSPE).\n",
    "* \"minimize-wape-mae\" - Minimize the combination of weighted absolute percentage error (WAPE) and mean-absolute-error (MAE).\n",
    "* \"minimize-quantile-loss\" - Minimize the quantile loss at the defined quantiles. (Set this objective to build quantile forecasts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3f3cd6d-be80-4f43-adc7-822086d7598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT: m5_nb3\n",
      "VERSION: v1\n",
      "OPTIMIZATION_OBJECTIVE: minimize-rmse\n",
      "TARGET_COLUMN: gross_quantity\n",
      "TIME_COLUMN: date\n",
      "SERIES_COLUMN: timeseries_id\n",
      "AVAILABLE_AT_FORECAST_COLS: ['event_name_1', 'year', 'event_type_1', 'month', 'dept_id', 'event_type_2', 'wday', 'state_id', 'snap_WI', 'snap_CA', 'snap_TX', 'product_id', 'date', 'event_name_2', 'location_id', 'weekday', 'cat_id']\n",
      "FORECAST_HORIZON: 14\n",
      "FORECAST_GRANULARITY: day\n",
      "CONTEXT_WINDOW: 14\n",
      "TARGET_COLUMN: gross_quantity\n",
      "TARGET_COLUMN: gross_quantity\n"
     ]
    }
   ],
   "source": [
    "# TODO - edit these\n",
    "\n",
    "# forecast spec\n",
    "FORECAST_GRANULARITY = 'DAY'\n",
    "DATA_GRANULARITY_COUNT=1\n",
    "FORECAST_HORIZON = 14\n",
    "CONTEXT_WINDOW = 14\n",
    "forecast_test_length = 14\n",
    "forecast_val_length = 14\n",
    "\n",
    "# model config\n",
    "OPTIMIZATION_OBJECTIVE=\"minimize-rmse\"\n",
    "\n",
    "# job spec\n",
    "MILLI_NODE_HRS=1000\n",
    "HOLIDAY_REGIONS=['GLOBAL', 'NA', 'US']\n",
    "\n",
    "# export eval set BQ destination\n",
    "f\"bq://{PROJECT_ID}:{BQ_DATASET}:{BQ_TABLE}_automl_{VERSION}\",\n",
    "\n",
    "print(f\"EXPERIMENT: {EXPERIMENT}\")\n",
    "print(f\"VERSION: {VERSION}\")\n",
    "print(f\"OPTIMIZATION_OBJECTIVE: {OPTIMIZATION_OBJECTIVE}\")\n",
    "print(f\"TARGET_COLUMN: {TARGET_COLUMN}\")\n",
    "print(f\"TIME_COLUMN: {TIME_COLUMN}\")\n",
    "print(f\"SERIES_COLUMN: {SERIES_COLUMN}\")\n",
    "print(f\"AVAILABLE_AT_FORECAST_COLS: {AVAILABLE_AT_FORECAST_COLS}\")\n",
    "print(f\"FORECAST_HORIZON: {FORECAST_HORIZON}\")\n",
    "print(f\"FORECAST_GRANULARITY: {FORECAST_GRANULARITY.lower()}\")\n",
    "print(f\"CONTEXT_WINDOW: {CONTEXT_WINDOW}\")\n",
    "print(f\"TARGET_COLUMN: {TARGET_COLUMN}\")\n",
    "print(f\"TARGET_COLUMN: {TARGET_COLUMN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da3ac7-c181-4345-aa31-c1dd0aca902c",
   "metadata": {},
   "source": [
    "## create and submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "003122b6-1e37-4834-86f4-30946c7f1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_job = vertex_ai.AutoMLForecastingTrainingJob(\n",
    "    display_name = f'{EXPERIMENT}_{VERSION}_training',\n",
    "    optimization_objective=OPTIMIZATION_OBJECTIVE,\n",
    "    column_specs = COL_TRANSFORMS,\n",
    "    labels = {'experiment':f'{EXPERIMENT}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81823ad5-6d87-4508-b6dd-b3d1095bf84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7132435584676528128?project=934903580331\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob run completed. Resource name: projects/934903580331/locations/us-central1/trainingPipelines/7132435584676528128\n",
      "Model available at projects/934903580331/locations/us-central1/models/7005333827212017664\n",
      "Exported examples available at:\n",
      "bq://hybrid-vertex.m5_us.sdk_train_automl\n"
     ]
    }
   ],
   "source": [
    "forecast=forecast_job.run(\n",
    "    dataset=dataset,\n",
    "    target_column=TARGET_COLUMN,\n",
    "    time_column=TIME_COLUMN,\n",
    "    time_series_identifier_column=SERIES_COLUMN,\n",
    "    unavailable_at_forecast_columns=UNAVAILABLE_AT_FORECAST_COLS,\n",
    "    available_at_forecast_columns=AVAILABLE_AT_FORECAST_COLS,\n",
    "    forecast_horizon=FORECAST_HORIZON,\n",
    "    data_granularity_unit=FORECAST_GRANULARITY.lower(),\n",
    "    data_granularity_count=DATA_GRANULARITY_COUNT,\n",
    "    predefined_split_column_name=\"splits\",\n",
    "    context_window = CONTEXT_WINDOW,\n",
    "    export_evaluated_data_items=True,\n",
    "    export_evaluated_data_items_bigquery_destination_uri=f\"bq://{PROJECT_ID}:{BQ_DATASET}:{BQ_TABLE}_automl\",\n",
    "    validation_options=\"fail-pipeline\",\n",
    "    budget_milli_node_hours = MILLI_NODE_HRS,\n",
    "    model_display_name=f\"{EXPERIMENT}_{BQ_TABLE}_{VERSION}\",\n",
    "    model_labels={'experiment':f'{EXPERIMENT}'},\n",
    "    holiday_regions=HOLIDAY_REGIONS,\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37cb9850-877b-4b99-bf44-635e14acc872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORECAST_MODEL_RSC_NAME: projects/934903580331/locations/us-central1/models/7005333827212017664\n"
     ]
    }
   ],
   "source": [
    "FORECAST_MODEL_RSC_NAME = forecast.resource_name\n",
    "print(f\"FORECAST_MODEL_RSC_NAME: {FORECAST_MODEL_RSC_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae884b-5da4-4d72-bcbe-ef497a74a507",
   "metadata": {},
   "source": [
    "## default Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "addc6b82-5be2-4e46-840b-72268e78412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'projects/934903580331/locations/us-central1/models/7005333827212017664@1/evaluations/6460567139166462004', 'metricsSchemaUri': 'gs://google-cloud-aiplatform/schema/modelevaluation/forecasting_metrics_1.0.0.yaml', 'metrics': {'rootMeanSquaredLogError': 0.5136268, 'meanAbsolutePercentageError': 319171650.0, 'rootMeanSquaredError': 2.0453851, 'weightedAbsolutePercentageError': 69.91979, 'meanAbsoluteError': 1.0452875, 'rootMeanSquaredPercentageError': 736705400.0, 'rSquared': 0.6968847}, 'createTime': '2023-03-29T02:59:47.699501Z', 'modelExplanation': {'meanAttributions': [{'featureAttributions': {'weekday': 0.03940948912202448, 'snap_WI': 0.020936330299017765, 'snap_CA': 0.018657082080329047, 'event_name_1': 0.0034677933750684176, 'month': 0.002100957425595409, 'cat_id': 0.0151225464475233, 'wday': 0.034578529526502484, 'snap_TX': 0.002699295153349477, 'event_type_2': 5.7893715215150484e-11, 'year': 0.008367055008976831, 'dept_id': 0.05254432222548768, 'event_type_1': 0.0018022876123545675, 'event_name_2': 4.185034507523397e-09, 'date': 0.07236677741907574, 'sell_price': 0.07005297926625154, 'location_id': 0.02470068564322292, 'state_id': 0.015165019089078422, 'gross_quantity': 1.2704826716428264, 'product_id': 0.059260100279855406}}]}}\n"
     ]
    }
   ],
   "source": [
    "forecast_EVALS = forecast.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in forecast_EVALS:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c4a28f-2c50-4145-a3f4-26afccdd6751",
   "metadata": {},
   "source": [
    "### retrieve default model evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e87dca28-7a05-4b04-b0e7-c5f60d39613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rootMeanSquaredLogError': [0.5136268],\n",
       " 'rSquared': [0.6968847],\n",
       " 'meanAbsoluteError': [1.0452875],\n",
       " 'meanAbsolutePercentageError': [319171650.0],\n",
       " 'rootMeanSquaredError': [2.0453851],\n",
       " 'rootMeanSquaredPercentageError': [736705400.0],\n",
       " 'weightedAbsolutePercentageError': [69.91979]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop any metrics the ARIMA pipeline doesn't support yet.\n",
    "model_evaluation = list(forecast.list_model_evaluations())[0]\n",
    "metrics_dict = {k: [v] for k, v in dict(model_evaluation.metrics).items()}\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc55c0-6871-418f-bd22-cfdc742b5553",
   "metadata": {},
   "source": [
    "## log metrics to Vertex AI Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0eab6a22-789b-4eab-94d8-21c8bbbf180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/m5-nb3-run-20230329055257 to Experiment: m5-nb3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/m5-nb3-run-20230329055257 to Experiment: m5-nb3\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# create run name\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "EXPERIMENT_RUN_NAME = f\"run-{TIMESTAMP}\"\n",
    "\n",
    "# log params and metrics to dicts\n",
    "params = {}\n",
    "params[\"budget_hrs\"] = MILLI_NODE_HRS\n",
    "params[\"horizon\"] = FORECAST_HORIZON\n",
    "params[\"context_window\"] = CONTEXT_WINDOW\n",
    "\n",
    "metrics = {}\n",
    "metrics[\"MAE\"] = metrics_dict['meanAbsoluteError'][0]\n",
    "metrics[\"RMSE\"] = metrics_dict['rootMeanSquaredError'][0]\n",
    "metrics[\"MAPE\"] = metrics_dict['meanAbsolutePercentageError'][0]\n",
    "metrics[\"rSquared\"] = metrics_dict['rSquared'][0]\n",
    "metrics[\"RMSLE\"] = metrics_dict['rootMeanSquaredLogError'][0]\n",
    "metrics[\"WAPE\"] = metrics_dict['weightedAbsolutePercentageError'][0]\n",
    "\n",
    "# # Create and log experiment\n",
    "vertex_ai.init(experiment=EXPERIMENT.replace(\"_\",\"-\"))\n",
    "\n",
    "with vertex_ai.start_run(EXPERIMENT_RUN_NAME) as my_run:\n",
    "    my_run.log_metrics(metrics)\n",
    "    my_run.log_params(params)\n",
    "\n",
    "    vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad862a1b-bb14-4bfe-a0c4-a9c1856202b6",
   "metadata": {},
   "source": [
    "## Using The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "568e014c-561b-4f38-a752-30894b914b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeseries_id</th>\n",
       "      <th>date</th>\n",
       "      <th>prediction_lead_days</th>\n",
       "      <th>predicted_on_date</th>\n",
       "      <th>gross_quantity</th>\n",
       "      <th>predicted_gross_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_681_CA_3</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>34</td>\n",
       "      <td>32.296787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOUSEHOLD_1_465_TX_2</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>16</td>\n",
       "      <td>11.202044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_2_399_TX_3</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.371759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_3_413_WI_1</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>15</td>\n",
       "      <td>6.104545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_3_234_TX_2</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>24</td>\n",
       "      <td>16.150120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426855</th>\n",
       "      <td>FOODS_3_329_WI_1</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>8</td>\n",
       "      <td>10.064318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426856</th>\n",
       "      <td>FOODS_3_692_CA_2</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>8</td>\n",
       "      <td>3.398916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426857</th>\n",
       "      <td>HOUSEHOLD_1_459_WI_3</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>8</td>\n",
       "      <td>9.950679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426858</th>\n",
       "      <td>HOUSEHOLD_1_351_CA_2</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.783339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426859</th>\n",
       "      <td>HOUSEHOLD_1_514_TX_2</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>8</td>\n",
       "      <td>6.545293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426860 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timeseries_id        date  prediction_lead_days  \\\n",
       "0           FOODS_3_681_CA_3  2016-05-10                     0   \n",
       "1       HOUSEHOLD_1_465_TX_2  2016-05-10                     0   \n",
       "2           FOODS_2_399_TX_3  2016-05-11                     0   \n",
       "3           FOODS_3_413_WI_1  2016-05-11                     0   \n",
       "4           FOODS_3_234_TX_2  2016-05-12                     0   \n",
       "...                      ...         ...                   ...   \n",
       "426855      FOODS_3_329_WI_1  2016-05-12                     0   \n",
       "426856      FOODS_3_692_CA_2  2016-05-13                     0   \n",
       "426857  HOUSEHOLD_1_459_WI_3  2016-05-13                     0   \n",
       "426858  HOUSEHOLD_1_351_CA_2  2016-05-17                     0   \n",
       "426859  HOUSEHOLD_1_514_TX_2  2016-05-10                     0   \n",
       "\n",
       "       predicted_on_date  gross_quantity  predicted_gross_quantity  \n",
       "0             2016-05-10              34                 32.296787  \n",
       "1             2016-05-10              16                 11.202044  \n",
       "2             2016-05-11               9                  0.371759  \n",
       "3             2016-05-11              15                  6.104545  \n",
       "4             2016-05-12              24                 16.150120  \n",
       "...                  ...             ...                       ...  \n",
       "426855        2016-05-12               8                 10.064318  \n",
       "426856        2016-05-13               8                  3.398916  \n",
       "426857        2016-05-13               8                  9.950679  \n",
       "426858        2016-05-17               8                  3.783339  \n",
       "426859        2016-05-10               8                  6.545293  \n",
       "\n",
       "[426860 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    RAW AS (\n",
    "        SELECT \n",
    "            DATE({TIME_COLUMN}) as {TIME_COLUMN}, \n",
    "            DATE(predicted_on_date) as predicted_on_date, \n",
    "            CAST({TARGET_COLUMN} as INT64) AS {TARGET_COLUMN}, \n",
    "            #splits, \n",
    "            {SERIES_COLUMN}, \n",
    "            predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "        FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_automl`\n",
    "    ),\n",
    "    LEAD AS (\n",
    "        SELECT \n",
    "            *, \n",
    "            DATE_DIFF({TIME_COLUMN}, predicted_on_date, {FORECAST_GRANULARITY}) as prediction_lead_days\n",
    "        FROM RAW\n",
    "    ),\n",
    "    LEFTSIDE AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            min(prediction_lead_days) as prediction_lead_days\n",
    "        FROM LEAD\n",
    "        GROUP BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    )\n",
    "SELECT *\n",
    "FROM LEFTSIDE\n",
    "LEFT OUTER JOIN LEAD\n",
    "USING ({SERIES_COLUMN}, {TIME_COLUMN}, prediction_lead_days)\n",
    "\"\"\"\n",
    "autoML = bq_client.query(query).to_dataframe()\n",
    "autoML\n",
    "\n",
    "# print to run in BigQuery console\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2114d9f7-580c-44fb-b2c8-34bccb95f975",
   "metadata": {},
   "source": [
    "### Review Custom Metrics with SQL\n",
    "\n",
    "Some common metrics for evaluating forecasting effectiveness are \n",
    "- MAPE, or Mean Absolute Percentage Error\n",
    "    - $\\textrm{MAPE} = \\frac{1}{n}\\sum{\\frac{\\mid(actual - forecast)\\mid}{actual}}$\n",
    "- MAE, or Mean Absolute Error\n",
    "     - $\\textrm{MAE} = \\frac{1}{n}\\sum{\\mid(actual - forecast)\\mid}$\n",
    "- MAE divided by average demand so it yields a % like MAPE\n",
    "    - $\\textrm{pMAE} = \\frac{\\sum{\\mid(actual - forecast)\\mid}}{\\sum{actual}}$\n",
    "- MSE, or Mean Squared Error\n",
    "    - $\\textrm{MSE} = \\frac{1}{n}\\sum{(actual-forecast)^2}$\n",
    "- RMSE, or Root Mean Squared Error\n",
    "    - $\\textrm{RMSE} = \\sqrt{\\frac{1}{n}\\sum{(actual-forecast)^2}}$\n",
    "- RMSE divided by average demand so it yeilds a % like MAPE\n",
    "    - $\\textrm{pRMSE} = \\frac{\\sqrt{\\frac{1}{n}\\sum{(actual-forecast)^2}}}{\\frac{1}{n}\\sum{actual}}$\n",
    "\n",
    "It can be helpful to explicity caculate these to make comparison between datasets and models fair.  This section demonstration these calculation with SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf1847d0-02ad-4e9f-8947-a8d1b36bbb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH\n",
      "    FORECASTS AS (\n",
      "        SELECT DATE(date) as date, \n",
      "            DATE(predicted_on_date) as predicted_on_date, \n",
      "            CAST(gross_quantity as INT64) AS gross_quantity, \n",
      "            #splits,\n",
      "            timeseries_id, \n",
      "            predicted_gross_quantity.value as predicted_gross_quantity\n",
      "        FROM `hybrid-vertex.m5_us.sdk_train_automl`\n",
      "    ),\n",
      "    LEAD_DAYS AS (\n",
      "        SELECT *, DATE_DIFF(date, predicted_on_date, DAY) as prediction_lead_days\n",
      "        FROM FORECASTS\n",
      "    ),\n",
      "    LATEST AS (\n",
      "        SELECT timeseries_id, date, min(prediction_lead_days) as prediction_lead_days\n",
      "        FROM LEAD_DAYS\n",
      "        GROUP BY timeseries_id, date\n",
      "    ),\n",
      "    DIFFS AS (\n",
      "        SELECT \n",
      "            timeseries_id, \n",
      "            date, \n",
      "            'forecast' as time_series_type,\n",
      "            predicted_gross_quantity as forecast_value,\n",
      "            gross_quantity as actual_value,\n",
      "            (gross_quantity - predicted_gross_quantity) as diff\n",
      "        FROM LATEST\n",
      "        LEFT OUTER JOIN LEAD_DAYS\n",
      "        USING (timeseries_id, date, prediction_lead_days)    \n",
      "    )\n",
      "SELECT timeseries_id, time_series_type, \n",
      "    AVG(SAFE_DIVIDE(ABS(diff), actual_value)) as MAPE,\n",
      "    AVG(ABS(diff)) as MAE,\n",
      "    SAFE_DIVIDE(SUM(ABS(diff)),SUM(actual_value)) as pMAE,\n",
      "    AVG(POW(diff, 2)) as MSE,\n",
      "    SQRT(AVG(POW(diff, 2))) as RMSE,\n",
      "    SAFE_DIVIDE(SQRT( AVG( POW(diff, 2) ) ) , AVG(actual_value) ) as pRMSE\n",
      "FROM DIFFS\n",
      "GROUP BY timeseries_id, time_series_type\n",
      "ORDER BY timeseries_id, time_series_type    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    FORECASTS AS (\n",
    "        SELECT DATE({TIME_COLUMN}) as {TIME_COLUMN}, \n",
    "            DATE(predicted_on_date) as predicted_on_date, \n",
    "            CAST({TARGET_COLUMN} as INT64) AS {TARGET_COLUMN}, \n",
    "            #splits,\n",
    "            {SERIES_COLUMN}, \n",
    "            predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "        FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_automl`\n",
    "    ),\n",
    "    LEAD_DAYS AS (\n",
    "        SELECT *, DATE_DIFF({TIME_COLUMN}, predicted_on_date, {FORECAST_GRANULARITY}) as prediction_lead_days\n",
    "        FROM FORECASTS\n",
    "    ),\n",
    "    LATEST AS (\n",
    "        SELECT {SERIES_COLUMN}, {TIME_COLUMN}, min(prediction_lead_days) as prediction_lead_days\n",
    "        FROM LEAD_DAYS\n",
    "        GROUP BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    ),\n",
    "    DIFFS AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            'forecast' as time_series_type,\n",
    "            predicted_{TARGET_COLUMN} as forecast_value,\n",
    "            {TARGET_COLUMN} as actual_value,\n",
    "            ({TARGET_COLUMN} - predicted_{TARGET_COLUMN}) as diff\n",
    "        FROM LATEST\n",
    "        LEFT OUTER JOIN LEAD_DAYS\n",
    "        USING ({SERIES_COLUMN}, {TIME_COLUMN}, prediction_lead_days)    \n",
    "    )\n",
    "SELECT {SERIES_COLUMN}, time_series_type, \n",
    "    AVG(SAFE_DIVIDE(ABS(diff), actual_value)) as MAPE,\n",
    "    AVG(ABS(diff)) as MAE,\n",
    "    SAFE_DIVIDE(SUM(ABS(diff)),SUM(actual_value)) as pMAE,\n",
    "    AVG(POW(diff, 2)) as MSE,\n",
    "    SQRT(AVG(POW(diff, 2))) as RMSE,\n",
    "    SAFE_DIVIDE(SQRT( AVG( POW(diff, 2) ) ) , AVG(actual_value) ) as pRMSE\n",
    "FROM DIFFS\n",
    "GROUP BY {SERIES_COLUMN}, time_series_type\n",
    "ORDER BY {SERIES_COLUMN}, time_series_type    \n",
    "\"\"\"\n",
    "\n",
    "# customMetrics = bq_client.query(query = query).to_dataframe()\n",
    "# customMetrics\n",
    "\n",
    "# print to run in BigQuery console\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a2a3e-9967-430d-acc1-ad17224bfb4d",
   "metadata": {},
   "source": [
    "Overall Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef0784de-9c1e-4bf7-86ec-1d4cfdefaadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_series_type</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>pMAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>pRMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forecast</td>\n",
       "      <td>0.577317</td>\n",
       "      <td>1.028049</td>\n",
       "      <td>0.696077</td>\n",
       "      <td>3.974805</td>\n",
       "      <td>1.993691</td>\n",
       "      <td>1.349898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  time_series_type      MAPE       MAE      pMAE       MSE      RMSE     pRMSE\n",
       "0         forecast  0.577317  1.028049  0.696077  3.974805  1.993691  1.349898"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "WITH\n",
    "    FORECASTS AS (\n",
    "        SELECT \n",
    "            DATE({TIME_COLUMN}) as {TIME_COLUMN}, \n",
    "            DATE(predicted_on_date) as predicted_on_date, \n",
    "            CAST({TARGET_COLUMN} as INT64) AS {TARGET_COLUMN}, \n",
    "            #splits, \n",
    "            {SERIES_COLUMN}, \n",
    "            predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "        FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_automl`\n",
    "    ),\n",
    "    LEAD_DAYS AS (\n",
    "        SELECT \n",
    "            *, \n",
    "            DATE_DIFF({TIME_COLUMN}, \n",
    "            predicted_on_date, \n",
    "            {FORECAST_GRANULARITY}) as prediction_lead_days\n",
    "        FROM FORECASTS\n",
    "    ),\n",
    "    LATEST AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            min(prediction_lead_days) as prediction_lead_days\n",
    "        FROM LEAD_DAYS\n",
    "        GROUP BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    ),\n",
    "    DIFFS AS (\n",
    "        SELECT \n",
    "            {SERIES_COLUMN}, \n",
    "            {TIME_COLUMN}, \n",
    "            'forecast' as time_series_type,\n",
    "            predicted_{TARGET_COLUMN} as forecast_value,\n",
    "            {TARGET_COLUMN} as actual_value,\n",
    "            ({TARGET_COLUMN} - predicted_{TARGET_COLUMN}) as diff\n",
    "        FROM LATEST\n",
    "        LEFT OUTER JOIN LEAD_DAYS\n",
    "        USING ({SERIES_COLUMN}, {TIME_COLUMN}, prediction_lead_days)    \n",
    "    )\n",
    "SELECT time_series_type, \n",
    "    AVG( SAFE_DIVIDE(ABS( diff ) , actual_value) ) as MAPE,\n",
    "    AVG(ABS(diff)) as MAE,\n",
    "    SAFE_DIVIDE(SUM( ABS( diff ) ) , SUM(actual_value) )  as pMAE,\n",
    "    AVG(POW(diff, 2)) as MSE,\n",
    "    SQRT(AVG(POW(diff, 2))) as RMSE,\n",
    "    SAFE_DIVIDE(SQRT( AVG( POW(diff, 2) ) ) , AVG(actual_value) )  as pRMSE\n",
    "FROM DIFFS\n",
    "GROUP BY time_series_type\n",
    "ORDER BY time_series_type    \n",
    "\"\"\"\n",
    "customMetricsOverall = bq_client.query(query = query).to_dataframe()\n",
    "customMetricsOverall\n",
    "\n",
    "# print to run in BigQuery console\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "641de1f2-fa29-4386-9d83-3096861c50a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/m5-nb3-v2-run-20230329055639 to Experiment: m5-nb3-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.metadata.experiment_resources:Associating projects/934903580331/locations/us-central1/metadataStores/default/contexts/m5-nb3-v2-run-20230329055639 to Experiment: m5-nb3-v2\n"
     ]
    }
   ],
   "source": [
    "# create run name\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "EXPERIMENT_RUN_NAME = f\"run-{TIMESTAMP}\"\n",
    "\n",
    "# log params and metrics to dicts\n",
    "params = {}\n",
    "params[\"budget_hrs\"] = MILLI_NODE_HRS\n",
    "params[\"horizon\"] = FORECAST_HORIZON\n",
    "params[\"context_window\"] = CONTEXT_WINDOW\n",
    "\n",
    "metrics = {}\n",
    "metrics[\"MAPE\"] = customMetricsOverall['MAPE'][0]\n",
    "metrics[\"MAE\"] = customMetricsOverall['MAE'][0]\n",
    "metrics[\"pMAE\"] = customMetricsOverall['pMAE'][0]\n",
    "metrics[\"MSE\"] = customMetricsOverall['MSE'][0]\n",
    "metrics[\"RMSE\"] = customMetricsOverall['RMSE'][0]\n",
    "metrics[\"pRMSE\"] = customMetricsOverall['pRMSE'][0]\n",
    "\n",
    "# # Create and log experiment\n",
    "vertex_ai.init(experiment=EXPERIMENT.replace(\"_\",\"-\"))\n",
    "\n",
    "with vertex_ai.start_run(EXPERIMENT_RUN_NAME) as my_run:\n",
    "    my_run.log_metrics(metrics)\n",
    "    my_run.log_params(params)\n",
    "\n",
    "    vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1366da1-29c3-4ad0-9376-c83b65bba9ac",
   "metadata": {},
   "source": [
    "## Get Forecasted Values for Future Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0cde221-e9d6-4ab0-901a-25315be99bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f4aac694990>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_automl_batch_input` AS\n",
    "WITH\n",
    "    DATELIST AS (\n",
    "        SELECT *\n",
    "        FROM (SELECT DISTINCT {SERIES_COLUMN} FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_source`) A\n",
    "        CROSS JOIN (SELECT * \n",
    "                    FROM UNNEST(GENERATE_DATE_ARRAY(\n",
    "                                    DATE_SUB((SELECT MAX({TIME_COLUMN}) FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_prepped`), INTERVAL {CONTEXT_WINDOW-1} {FORECAST_GRANULARITY}),\n",
    "                                    DATE_ADD((SELECT MAX({TIME_COLUMN}) FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}_prepped`), INTERVAL {FORECAST_HORIZON} {FORECAST_GRANULARITY}),\n",
    "                                    INTERVAL 1 {FORECAST_GRANULARITY}\n",
    "                                )\n",
    "                            ) AS {TIME_COLUMN}\n",
    "                    ) B\n",
    "    ),\n",
    "    ADDTARGET AS (\n",
    "        SELECT *\n",
    "        FROM DATELIST\n",
    "        LEFT OUTER JOIN (SELECT {SERIES_COLUMN}, {TIME_COLUMN}, {TARGET_COLUMN} FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_source`)\n",
    "        USING ({SERIES_COLUMN}, {TIME_COLUMN})\n",
    "        ORDER BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "    ),\n",
    "    LOCF AS (\n",
    "        SELECT \n",
    "          {SERIES_COLUMN}, \n",
    "          {TIME_COLUMN},\n",
    "          LAST_VALUE({TARGET_COLUMN} IGNORE NULLS) OVER (PARTITION BY {SERIES_COLUMN} ORDER BY {TIME_COLUMN} ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as {TARGET_COLUMN}\n",
    "        FROM ADDTARGET\n",
    "    )\n",
    "SELECT \n",
    "    {SERIES_COLUMN}, \n",
    "    {TIME_COLUMN},\n",
    "    CASE\n",
    "        WHEN {TIME_COLUMN} > (SELECT MAX({TIME_COLUMN}) FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_source`) THEN NULL\n",
    "        ELSE {TARGET_COLUMN}\n",
    "    END AS {TARGET_COLUMN}\n",
    "FROM LOCF\n",
    "ORDER BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "# \"\"\"\n",
    "job = bq_client.query(query = query)\n",
    "job.result()\n",
    "\n",
    "# print to run in BigQuery console\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fa192-fd4d-4289-88aa-3caa1930d6de",
   "metadata": {},
   "source": [
    "# Batch Prediction Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eb43564a-e609-4eee-8ff5-df9f6dd238bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob created. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this BatchPredictionJob in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpj = aiplatform.BatchPredictionJob('projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/732046457997099008?project=934903580331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/732046457997099008?project=934903580331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "# batchjob = vertex_ai.BatchPredictionJob.create(\n",
    "batch_prediction_job = forecast.batch_predict(\n",
    "    job_display_name = f'{EXPERIMENT}_automl_{CONTEXT_WINDOW}_{VERSION}',\n",
    "    # model_name = forecast.resource_name,\n",
    "    instances_format = 'bigquery',\n",
    "    predictions_format = 'bigquery',\n",
    "    bigquery_source = f\"bq://{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_automl_batch_input\",\n",
    "    bigquery_destination_prefix = f\"bq://{PROJECT_ID}.{BQ_DATASET}\",\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550f71e-9dff-4306-83ac-a3dc6893bccb",
   "metadata": {},
   "source": [
    "## Process Predicted Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "28d5d650-3019-44e2-9a95-2ded80cd02db",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchPredictionJob' object has no attribute 'bigquery_output_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_16835/4025992534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# batchjob.output_info.bigquery_output_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigquery_output_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchPredictionJob' object has no attribute 'bigquery_output_table'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchPredictionJob run completed. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob run completed. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/732046457997099008\n"
     ]
    }
   ],
   "source": [
    "# batchjob.output_info.bigquery_output_table\n",
    "batch_prediction_job.bigquery_output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e81b61fb-d181-42ad-8f01-0ecaf67caa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bq://hybrid-vertex.m5_us.predictions_2023_03_28T22_01_23_629Z_734'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_predict_bq_output_uri = \"{}.{}\".format(\n",
    "    batch_prediction_job.output_info.bigquery_output_dataset,\n",
    "    batch_prediction_job.output_info.bigquery_output_table\n",
    ")\n",
    "\n",
    "batch_predict_bq_output_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f25323af-fd5c-494f-a9f7-0157ebda7245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 Not found: Table hybrid-vertex:m5_us.predictions_2023_03_28T22_01_23_629Z_734 was not found in location US\n\nLocation: US\nJob ID: 71a25984-1485-443e-b435-578f379d509e\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_16835/2710778957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print to run in BigQuery console\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1497\u001b[0m                 \u001b[0mdo_get_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_get_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m             \u001b[0mdo_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAPICallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             )\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mdo_get_result\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1487\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m                 \u001b[0;31m# Since the job could already be \"done\" (e.g. got a finished job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/bigquery/job/base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDEFAULT_RETRY\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Not found: Table hybrid-vertex:m5_us.predictions_2023_03_28T22_01_23_629Z_734 was not found in location US\n\nLocation: US\nJob ID: 71a25984-1485-443e-b435-578f379d509e\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_automl_batch_output` AS\n",
    "    SELECT {SERIES_COLUMN}, DATE({TIME_COLUMN}) as {TIME_COLUMN}, predicted_{TARGET_COLUMN}.value as predicted_{TARGET_COLUMN}\n",
    "    FROM `{PROJECT_ID}.{BQ_DATASET}.{batch_prediction_job.output_info.bigquery_output_table}`\n",
    "\"\"\"\n",
    "job = bq_client.query(query = query)\n",
    "job.result()\n",
    "\n",
    "# print to run in BigQuery console\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e02d6-6ae0-45d8-aa67-9ae473748ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_automl_batch_output`\n",
    "    ORDER BY {SERIES_COLUMN}, {TIME_COLUMN}\n",
    "\"\"\"\n",
    "predict = bq_client.query(query = query).to_dataframe()\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1399a0-16e1-4471-9693-5603526ce792",
   "metadata": {},
   "source": [
    "## Review Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f1c08-4ffe-484a-a31b-00ca62cbafe6",
   "metadata": {},
   "source": [
    "### Retrieve the Forecasting Data (raw series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81bd16-76f3-4bce-bd04-c637d71e4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO\n",
    "\n",
    "# query = f\"\"\"\n",
    "# SELECT start_station_name, date, splits, num_trips\n",
    "# FROM `{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE_PLAN}_prepped`\n",
    "# ORDER by start_station_name, date\n",
    "# \"\"\"\n",
    "# rawSeries = bigquery.query(query = query).to_dataframe()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
