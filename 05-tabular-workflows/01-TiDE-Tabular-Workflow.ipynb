{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dc312e-aa9e-4d09-944f-100eb7ee6509",
   "metadata": {},
   "source": [
    "# Demand Forecasting with Vertex Forecast on Tabular Workflows\n",
    "\n",
    "**Objectives**\n",
    "* train with and forecast *Iowa liquor BigQuery public dataset*\n",
    "* Use Tabular Workflows to orchestrate Vertex Forecast pipeline\n",
    "* Track experiments\n",
    "* Run model evalutaions for trained forecast models\n",
    "\n",
    "**TODOs**\n",
    "* `skip architecture search` in a retraining pipeline\n",
    "* upload v2 of a model and its evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44fd63e1-a2e6-44d8-a956-ee602430fbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install {USER_FLAG} google-cloud-aiplatform kfp google-cloud-pipeline-components --upgrade\n",
    "# !pip3 install --no-cache-dir {USER_FLAG} PyYAML==5.3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f338bf-70d6-4464-89dd-f87a45d99cce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.4.0\n",
      "google_cloud_pipeline_components version: 2.3.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa145e15-4650-4e2e-a5a8-ea9f71816ef1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "> use the prefix defined in 00-env-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb269c2c-5697-4f9e-ab5b-2bd9f0868ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_NEW_ASSETS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ae3b82-a0f7-41ed-9e2c-3a0552974d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = forecast-refresh-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"              # TODO\n",
    "PREFIX         = f'forecast-refresh-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1368cb3-2cdf-4571-9281-c847cead0318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"ucaip-haystack-vpc-network\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"forecast-refresh-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"forecast-refresh-v1-hybrid-vertex-gcs\"\n",
      "BUCKET_URI               = \"gs://forecast-refresh-v1-hybrid-vertex-gcs\"\n",
      "\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://forecast-refresh-v1-hybrid-vertex-gcs/data\"\n",
      "\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/934903580331/global/networks/ucaip-haystack-vpc-network\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# ! gcloud config set project $PROJECT_ID\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-gcs'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fd1173-e7ec-45d2-ac4f-ef6f35f1e18e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/\n",
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/config/\n"
     ]
    }
   ],
   "source": [
    "# For a list of available model metrics, go here:\n",
    "!gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d40790-c76b-4473-8b94-836131bd8cb4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adde7be5-33b5-4ea0-befe-96c895a42225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tide-twrkflow-eval-v1\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_TAG     = \"tide-twrkflow-eval\"\n",
    "EXPERIMENT_VERSION = \"v1\"\n",
    "\n",
    "EXPERIMENT_NAME = f\"{EXPERIMENT_TAG}-{EXPERIMENT_VERSION}\"\n",
    "\n",
    "print(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4986ccbd-7a47-4a01-a673-3fc0c706192d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import json\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from google.cloud import aiplatform, storage, bigquery\n",
    "\n",
    "# from google_cloud_pipeline_components.types.artifact_types import VertexDataset\n",
    "from google_cloud_pipeline_components.preview.automl.forecasting import \\\n",
    "    utils as automl_forecasting_utils\n",
    "\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "aiplatform.init(\n",
    "    experiment=EXPERIMENT_NAME, \n",
    "    project=PROJECT_ID, \n",
    "    location=REGION\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decaf69b-37d9-4319-a1a1-fef32de88954",
   "metadata": {},
   "source": [
    "## Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca65b389-d25a-4724-b2ea-c8c7cb3b88c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(DatasetReference('hybrid-vertex', 'tide_twrkflow_eval_v1'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGQUERY_DATASET_NAME = EXPERIMENT_NAME.replace(\"-\",\"_\")\n",
    "\n",
    "if CREATE_NEW_ASSETS:\n",
    "    ds = bigquery.Dataset(f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\")\n",
    "    ds.location = BQ_LOCATION\n",
    "    ds = bq_client.create_dataset(dataset = ds, exists_ok = False)\n",
    "    # print(ds.full_dataset_id)\n",
    "else:\n",
    "    ds = bigquery.Dataset(f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\")\n",
    "    \n",
    "ds \n",
    "# ds.dataset_id\n",
    "# ds.full_dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45f81e-9371-469e-97a7-6f747454df2e",
   "metadata": {},
   "source": [
    "## prepare train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe6f627-9f46-42c8-8699-1c7b8472e1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR = gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2907_22_44_752082\n"
     ]
    }
   ],
   "source": [
    "# Dataflow's fully qualified subnetwork name, when empty the default subnetwork will be used.\n",
    "dataflow_subnetwork           = None \n",
    "\n",
    "# Specifies whether Dataflow workers use public IP addresses.\n",
    "dataflow_use_public_ips       = True\n",
    "\n",
    "NOW                           = datetime.datetime.now().strftime(\"%d %H:%M:%S.%f\").replace(\" \",\"\").replace(\":\",\"_\").replace(\".\",\"_\")\n",
    "ROOT_DIR                      = f\"{BUCKET_URI}/automl_forecasting_pipeline/{EXPERIMENT_NAME}/run-{NOW}\"\n",
    "time_column                   = \"date\"\n",
    "time_series_identifier_column = \"store_name\"\n",
    "target_column                 = \"sale_dollars\"\n",
    "data_source_csv_filenames     = None\n",
    "\n",
    "print(f\"ROOT_DIR = {ROOT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aed5e93-24b2-4161-8666-da43fa78a872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available_at_forecast_columns    = ['date']\n",
      "unavailable_at_forecast_columns  = ['sale_dollars']\n",
      "time_series_attribute_columns    = ['city', 'zip_code', 'county']\n"
     ]
    }
   ],
   "source": [
    "data_source_bigquery_table_path = (\n",
    "    \"bq://bigquery-public-data.iowa_liquor_sales_forecasting.2020_sales_train\"\n",
    ")\n",
    "\n",
    "training_fraction = 0.8\n",
    "validation_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "\n",
    "predefined_split_key = None\n",
    "if predefined_split_key:\n",
    "    training_fraction = None\n",
    "    validation_fraction = None\n",
    "    test_fraction = None\n",
    "\n",
    "weight_column = None\n",
    "\n",
    "features = [\n",
    "    time_column,\n",
    "    target_column,\n",
    "    \"city\",\n",
    "    \"zip_code\",\n",
    "    \"county\",\n",
    "]\n",
    "\n",
    "available_at_forecast_columns = [time_column]\n",
    "unavailable_at_forecast_columns = [target_column]\n",
    "time_series_attribute_columns = [\"city\", \"zip_code\", \"county\"]\n",
    "\n",
    "forecast_horizon = 150\n",
    "context_window = 150\n",
    "\n",
    "print(f\"available_at_forecast_columns    = {available_at_forecast_columns}\")\n",
    "print(f\"unavailable_at_forecast_columns  = {unavailable_at_forecast_columns}\")\n",
    "print(f\"time_series_attribute_columns    = {time_series_attribute_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff50d5c-1bef-4f95-92ba-a5877d360460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformations       = {'auto': ['date', 'sale_dollars', 'city', 'zip_code', 'county'], 'numeric': [], 'categorical': [], 'text': [], 'timestamp': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformations = helpers.generate_auto_transformation(features)\n",
    "transformations = helpers.generate_transformation(auto_column_names=features)\n",
    "\n",
    "# TRANSFORM_CONFIG_PATH = f\"{ROOT_DIR}/transform_config_{NOW}.json\"\n",
    "# TRANSFORM_CONFIG_PATH = \"gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/run-28ec73a7-646e-420b-b883-2aa16ea2e518/transform_config_40ac07bd-c92b-4914-beda-18a382062acd.json\"\n",
    "\n",
    "print(f\"transformations       = {transformations}\\n\")\n",
    "# print(f\"TRANSFORM_CONFIG_PATH = {TRANSFORM_CONFIG_PATH}\")\n",
    "\n",
    "# helpers.write_to_gcs(TRANSFORM_CONFIG_PATH, json.dumps(transformations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ae7f8b-da1e-419c-b50a-17a69db9436e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/\n",
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/config/\n"
     ]
    }
   ],
   "source": [
    "# For a list of available model metrics, go here:\n",
    "!gsutil ls $BUCKET_URI/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca7d3f-7120-4f9c-9a69-eecd0aa3a307",
   "metadata": {},
   "source": [
    "# Vertex Forecast Training\n",
    "\n",
    "**Optimization Objectives** ([docs](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters#optimization-objectives))\n",
    "\n",
    "| Objective  | API                      | Use case |\n",
    "| :--------: | :------------:           | :------------------------------------- |\n",
    "| RMSE       | `minimize-rmse`          | Minimize root-mean-squared error (RMSE). Captures more extreme values accurately and is less biased when aggregating predictions.Default value. |\n",
    "| MAE        | `minimize-mae`           | Minimize mean-absolute error (MAE). Views extreme values as outliers with less impact on model. |\n",
    "| RMSLE      | `minimize-rmsle`         | Minimize root-mean-squared log error (RMSLE). Penalizes error on relative size rather than absolute value. Useful when both predicted and actual values can be large. |\n",
    "| RMSPE      | `minimize-rmspe`         | Minimize root-mean-squared percentage error (RMSPE). Captures a large range of values accurately. Similar to RMSE, but relative to target magnitude. Useful when the range of values is large. |\n",
    "| WAPE       | `minimize-wape-mae`      | Minimize the combination of weighted absolute percentage error (WAPE) and mean-absolute-error (MAE). Useful when the actual values are low. |\n",
    "| QUANTILE   | `minimize-quantile-loss` | Minimize the scaled pinball loss of the defined quantiles to quantify uncertainty in estimates. Quantile predictions quantify the uncertainty of predictions. They measure the likelihood of a prediction being within a range. |\n",
    "\n",
    "\n",
    "**TiDE on Vertex Tabluar Workflows**\n",
    "* [src](https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/preview/automl/forecasting/utils.py#L413)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd20af59-98bf-4f7d-855e-d7316aa0e512",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "* add `with dsl.ParallelFor(LIST) as cw:` for parallel jobs with diff params (e.g., statmike [example](https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20Forecasting/Vertex%20AI%20Pipelines%20-%20Forecasting%20Tournament%20with%20Kubeflow%20Pipelines%20(KFP).ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d5c8289-e747-4905-aa05-f2fd0db54eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID = tide-tide-twrkflow-eval-v1\n"
     ]
    }
   ],
   "source": [
    "# Number of weak models in the final ensemble model.\n",
    "num_selected_trials           = 5\n",
    "train_budget_milli_node_hours = 500  # 30 minutes\n",
    "\n",
    "optimization_objective        = \"minimize-wape-mae\" \n",
    "\n",
    "RUN_EVALUATION                = True\n",
    "\n",
    "PROBABILISTIC_INFER           = False\n",
    "# QUANTILES                     = [0.25, 0.5, 0.9] # [0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "\n",
    "JOB_ID                        = f\"tide-{EXPERIMENT_NAME}\"\n",
    "\n",
    "print(f\"JOB_ID = {JOB_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45834c-a982-4ef2-941e-080ee0c358b8",
   "metadata": {},
   "source": [
    "## (1) TiDE - full AutoML train & eval\n",
    "\n",
    "TiDE stands for \"Time series Dense Encoder\", which is a new model type in Vertex Forecasting and has the best training and inference performance while not sacrificing any model quality.\n",
    "\n",
    "For more details, please see https://ai.googleblog.com/2023/04/recent-advances-in-deep-long-horizon.html\n",
    "\n",
    "You will create a skip evaluation AutoML Forecasting pipeline with the following customizations:\n",
    "- Limit the hyperparameter search space\n",
    "- Change machine type and tuning / training parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5a824e-8e1a-40c3-8473-967e8264a398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/tide-tide-twrkflow-eval-v1\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/tide-tide-twrkflow-eval-v1')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tide-tide-twrkflow-eval-v1?project=934903580331\n",
      "Associating projects/934903580331/locations/us-central1/pipelineJobs/tide-tide-twrkflow-eval-v1 to Experiment: tide-twrkflow-eval-v1\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    template_path,\n",
    "    parameter_values,\n",
    ") = automl_forecasting_utils.get_time_series_dense_encoder_forecasting_pipeline_and_parameters(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    root_dir=ROOT_DIR,\n",
    "    target_column=target_column,\n",
    "    optimization_objective=optimization_objective,\n",
    "    transformations=transformations,\n",
    "    train_budget_milli_node_hours=train_budget_milli_node_hours,\n",
    "    data_source_csv_filenames=data_source_csv_filenames,\n",
    "    data_source_bigquery_table_path=data_source_bigquery_table_path,\n",
    "    weight_column=weight_column,\n",
    "    predefined_split_key=predefined_split_key,\n",
    "    training_fraction=training_fraction,\n",
    "    validation_fraction=validation_fraction,\n",
    "    test_fraction=test_fraction,\n",
    "    num_selected_trials=num_selected_trials,\n",
    "    time_column=time_column,\n",
    "    time_series_identifier_columns=[time_series_identifier_column],\n",
    "    time_series_attribute_columns=time_series_attribute_columns,\n",
    "    available_at_forecast_columns=available_at_forecast_columns,\n",
    "    unavailable_at_forecast_columns=unavailable_at_forecast_columns,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    context_window=context_window,\n",
    "    dataflow_subnetwork=dataflow_subnetwork,\n",
    "    dataflow_use_public_ips=dataflow_use_public_ips,\n",
    "    run_evaluation=RUN_EVALUATION,                          # set True to eval on test/valid set\n",
    "    evaluated_examples_bigquery_path=f'bq://{PROJECT_ID}.{BIGQUERY_DATASET_NAME}',\n",
    "    enable_probabilistic_inference=PROBABILISTIC_INFER,\n",
    "    \n",
    "    ### quantile forecast\n",
    "    # quantiles=QUANTILES,\n",
    "    \n",
    "    ### hierarchical forecast\n",
    "    # group_columns=XXXX,\n",
    "    # group_total_weight=XXXX,\n",
    "    # temporal_total_weight=XXXX,\n",
    "    # group_temporal_total_weight=XXXX,\n",
    ")\n",
    "\n",
    "# job_id = \"tide-forecasting-probabilistic-inference-{}\".format(uuid.uuid4())\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=JOB_ID,\n",
    "    location=REGION,  # launches the pipeline job in the specified region\n",
    "    template_path=template_path,\n",
    "    job_id=JOB_ID,\n",
    "    pipeline_root=ROOT_DIR,\n",
    "    parameter_values=parameter_values,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "# job.run(sync=False,experiment=EXPERIMENT_NAME)\n",
    "job.submit(\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d61abe6-89ed-4ec5-af1b-2e2dc259de40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/prob-infer-forecast-refresh-v1-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "daa5ff12-cec7-48ef-a76e-d040d2188093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature-transform-engine\n",
      "calculate-training-parameters-2\n",
      "get-predictions-column-2\n",
      "exit-handler-1\n",
      "model-upload-2\n",
      "model-evaluation-import-2\n",
      "string-not-empty\n",
      "get-or-create-model-description-2\n",
      "model-batch-predict-2\n",
      "tide-tide-twrkflow-eval-v1\n",
      "feature-attribution-2\n",
      "condition-2\n",
      "automl-forecasting-ensemble-2\n",
      "condition-4\n",
      "automl-forecasting-stage-1-tuner\n",
      "finalize-eval-quantile-parameters-2\n",
      "automl-tabular-finalizer\n",
      "training-configurator-and-validator\n",
      "get-prediction-image-uri-2\n",
      "model-evaluation-forecasting-2\n",
      "split-materialized-data\n",
      "condition-5\n",
      "model-batch-explanation-2\n",
      "set-optional-inputs\n",
      "table-to-uri-2\n"
     ]
    }
   ],
   "source": [
    "pipeline_task_details = job.task_details\n",
    "\n",
    "for task_deets in pipeline_task_details:\n",
    "    print(task_deets.task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0816dcdf-89e3-450c-9fa8-3e2b49539126",
   "metadata": {},
   "source": [
    "### Get trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f808277-2f71-4cd2-8d81-3a25a33c3a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_1_tuning_result_artifact_uri: gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2907_22_44_752082/934903580331/tide-tide-twrkflow-eval-v1/automl-forecasting-stage-1-tuner_206416678001573888/tuning_result_output\n",
      "forecasting_mp_model: <google.cloud.aiplatform.models.Model object at 0x7f639b10d7e0> \n",
      "resource name: projects/934903580331/locations/us-central1/models/7688328460153913344\n"
     ]
    }
   ],
   "source": [
    "stage_1_tuner_task = helpers.get_task_detail(\n",
    "    pipeline_task_details, \"automl-forecasting-stage-1-tuner\"\n",
    ")\n",
    "stage_1_tuning_result_artifact_uri = (\n",
    "    stage_1_tuner_task.outputs[\"tuning_result_output\"].artifacts[0].uri\n",
    ")\n",
    "print(f\"stage_1_tuning_result_artifact_uri: {stage_1_tuning_result_artifact_uri}\")\n",
    "\n",
    "# get uploaded model\n",
    "upload_model_task = helpers.get_task_detail(\n",
    "    pipeline_task_details, \"model-upload-2\"\n",
    ")\n",
    "\n",
    "forecasting_mp_model_artifact = (\n",
    "    upload_model_task.outputs[\"model\"].artifacts[0]\n",
    ")\n",
    "\n",
    "forecasting_mp_model = aiplatform.Model(forecasting_mp_model_artifact.metadata['resourceName'])\n",
    "print(f\"forecasting_mp_model: {forecasting_mp_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d93595-a1cb-4d14-9c8e-749de2eeed07",
   "metadata": {},
   "source": [
    "### Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81e85a50-7c05-44f2-a6e4-650d9c74edf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createTime': '2023-12-29T08:52:40.959126Z',\n",
      " 'displayName': 'Vertex Forecasting pipeline',\n",
      " 'metadata': {'evaluation_dataset_path': ['bq://hybrid-vertex.vertex_feature_transform_engine_staging_us.vertex_ai_fte_split_output_test_staging_id83e65c1dc39241eca34c763520380490'],\n",
      "              'evaluation_dataset_type': 'bigquery',\n",
      "              'pipeline_job_id': '8418345082247184384',\n",
      "              'pipeline_job_resource_name': 'projects/934903580331/locations/us-central1/pipelineJobs/tide-tide-twrkflow-eval-v1'},\n",
      " 'metrics': {'meanAbsoluteError': 4118.861,\n",
      "             'meanAbsolutePercentageError': 390.12265,\n",
      "             'rSquared': 0.55656505,\n",
      "             'rootMeanSquaredError': 9204.42,\n",
      "             'rootMeanSquaredLogError': 0.9453542,\n",
      "             'rootMeanSquaredPercentageError': 5200.477,\n",
      "             'weightedAbsolutePercentageError': 48.703373},\n",
      " 'metricsSchemaUri': 'gs://google-cloud-aiplatform/schema/modelevaluation/forecasting_metrics_1.0.0.yaml',\n",
      " 'modelExplanation': {'meanAttributions': [{'featureAttributions': {'city': 104.93280171834074,\n",
      "                                                                    'county': 60.114672924658564,\n",
      "                                                                    'date': 604.0033073745092,\n",
      "                                                                    'sale_dollars': 4886.854262410241,\n",
      "                                                                    'zip_code': 10.897589732644093}}]},\n",
      " 'name': 'projects/934903580331/locations/us-central1/models/7688328460153913344@1/evaluations/4012530462180865187'}\n"
     ]
    }
   ],
   "source": [
    "if RUN_EVALUATION:\n",
    "    forecast_EVALS = forecasting_mp_model.list_model_evaluations()\n",
    "\n",
    "    for model_evaluation in forecast_EVALS:\n",
    "        pprint(model_evaluation.to_dict())\n",
    "        \n",
    "else:\n",
    "    print(f\"Model evaluations were set to: {RUN_EVALUATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbea4232-0aa8-4056-8671-0911e9bec5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's evaluation metrics from training:\n",
      "\n",
      "metric: rSquared, value: 0.55656505\n",
      "\n",
      "metric: rootMeanSquaredError, value: 9204.42\n",
      "\n",
      "metric: meanAbsoluteError, value: 4118.861\n",
      "\n",
      "metric: weightedAbsolutePercentageError, value: 48.703373\n",
      "\n",
      "metric: rootMeanSquaredPercentageError, value: 5200.477\n",
      "\n",
      "metric: meanAbsolutePercentageError, value: 390.12265\n",
      "\n",
      "metric: rootMeanSquaredLogError, value: 0.9453542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_EVALUATION:\n",
    "    # Get evaluations\n",
    "    model_evaluations = forecasting_mp_model.list_model_evaluations()\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    for evaluation in model_evaluations:\n",
    "        evaluation = evaluation.to_dict()\n",
    "        print(\"Model's evaluation metrics from training:\\n\")\n",
    "        metrics = evaluation[\"metrics\"]\n",
    "        for metric in metrics.keys():\n",
    "            print(f\"metric: {metric}, value: {metrics[metric]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e9890-c0bd-42fd-b1d0-a7134fed090e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Optional) Log pipeline to Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d0d110-852f-4c2c-8c21-05697f6a3e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def log_pipeline_job_sample(\n",
    "#     experiment_name: str,\n",
    "#     run_name: str,\n",
    "#     pipeline_job: aiplatform.PipelineJob,\n",
    "#     project: str,\n",
    "#     location: str,\n",
    "# ):\n",
    "#     aiplatform.init(experiment=experiment_name, project=project, location=location)\n",
    "\n",
    "#     aiplatform.start_run(run=run_name, resume=True)\n",
    "\n",
    "#     aiplatform.log(pipeline_job=pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1b3b3-bfb8-472a-96d9-f071640280f5",
   "metadata": {},
   "source": [
    "## (2) TiDE - skip architecture search\n",
    "\n",
    "Instead of doing architecture search everytime, we can reuse the existing architecture search result. This could help:\n",
    "1. reducing the variation of the output model\n",
    "2. reducing training cost\n",
    "\n",
    "The existing architecture search result is stored in the `tuning_result_output` output of the `automl-forecasting-stage-1-tuner` component. You can manually input it or get it programmatically.\n",
    "\n",
    "**New Parameter**\n",
    "* `stage_1_tuning_result_artifact_uri` (str): - (Optional) URI of the hyperparameter tuning result from a previous pipeline run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03138e49-5579-44ec-947f-23e8bd0e3df2",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "1. First test passing just experiement name in pipeline job:\n",
    "\n",
    "```\n",
    "job.submit(\n",
    "    experiment=EXPERIMENT_NAME,\n",
    ")\n",
    "```\n",
    "\n",
    "2. Check experiments & model eval compare\n",
    "3. Specify `EXPERIMENT_RUN_NAME` is output in (2) not right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a39f117e-ae1f-4a0d-b9cf-bef34759b70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID: tide-skip-arch-tide-twrkflow-eval-v1-v1\n",
      "<google.cloud.aiplatform.models.Model object at 0x7f639b10d7e0> \n",
      "resource name: projects/934903580331/locations/us-central1/models/7688328460153913344\n",
      "ROOT_DIR: gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2909_01_42_271952\n"
     ]
    }
   ],
   "source": [
    "JOB_ID   = f\"tide-skip-arch-{EXPERIMENT_NAME}-v1\"\n",
    "\n",
    "NOW      = datetime.datetime.now().strftime(\"%d %H:%M:%S.%f\").replace(\" \",\"\").replace(\":\",\"_\").replace(\".\",\"_\")\n",
    "ROOT_DIR = f\"{BUCKET_URI}/automl_forecasting_pipeline/{EXPERIMENT_NAME}/run-{NOW}\"\n",
    "\n",
    "print(f\"JOB_ID: {JOB_ID}\")\n",
    "print(f\"ROOT_DIR: {ROOT_DIR}\")\n",
    "\n",
    "print(forecasting_mp_model)\n",
    "print(stage_1_tuning_result_artifact_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa79df78-efbd-4e4c-b412-35e246ee6b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/tide-skip-arch-tide-twrkflow-eval-v1-v1\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/tide-skip-arch-tide-twrkflow-eval-v1-v1')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tide-skip-arch-tide-twrkflow-eval-v1-v1?project=934903580331\n",
      "Associating projects/934903580331/locations/us-central1/pipelineJobs/tide-skip-arch-tide-twrkflow-eval-v1-v1 to Experiment: tide-twrkflow-eval-v1\n"
     ]
    }
   ],
   "source": [
    "# Number of weak models in the final ensemble model.\n",
    "num_selected_trials = 5\n",
    "\n",
    "train_budget_milli_node_hours = 250.0  # 15 minutes\n",
    "\n",
    "(\n",
    "    template_path,\n",
    "    parameter_values,\n",
    ") = automl_forecasting_utils.get_time_series_dense_encoder_forecasting_pipeline_and_parameters(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    root_dir=ROOT_DIR,\n",
    "    target_column=target_column,\n",
    "    optimization_objective=optimization_objective,\n",
    "    transformations=transformations,\n",
    "    train_budget_milli_node_hours=train_budget_milli_node_hours,\n",
    "    data_source_csv_filenames=data_source_csv_filenames,\n",
    "    data_source_bigquery_table_path=data_source_bigquery_table_path,\n",
    "    weight_column=weight_column,\n",
    "    predefined_split_key=predefined_split_key,\n",
    "    training_fraction=training_fraction,\n",
    "    validation_fraction=validation_fraction,\n",
    "    test_fraction=test_fraction,\n",
    "    num_selected_trials=num_selected_trials,\n",
    "    time_column=time_column,\n",
    "    time_series_identifier_columns=[time_series_identifier_column],\n",
    "    time_series_attribute_columns=time_series_attribute_columns,\n",
    "    available_at_forecast_columns=available_at_forecast_columns,\n",
    "    unavailable_at_forecast_columns=unavailable_at_forecast_columns,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    context_window=context_window,\n",
    "    dataflow_subnetwork=dataflow_subnetwork,\n",
    "    dataflow_use_public_ips=dataflow_use_public_ips,\n",
    "    stage_1_tuning_result_artifact_uri=stage_1_tuning_result_artifact_uri,\n",
    "    run_evaluation=RUN_EVALUATION,\n",
    "    evaluated_examples_bigquery_path=f'bq://{PROJECT_ID}.{BIGQUERY_DATASET_NAME}',\n",
    "    enable_probabilistic_inference=PROBABILISTIC_INFER,\n",
    ")\n",
    "\n",
    "# job_id = \"tide-forecasting-skip-architecture-search-{}\".format(uuid.uuid4())\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=JOB_ID,\n",
    "    location=REGION,  # launches the pipeline job in the specified region\n",
    "    template_path=template_path,\n",
    "    job_id=JOB_ID,\n",
    "    pipeline_root=ROOT_DIR,\n",
    "    parameter_values=parameter_values,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "# job.run(sync=False,experiment=EXPERIMENT_NAME)\n",
    "job.submit(\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebf090b6-6674-4cac-b1cb-7f0f45bfd8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2907_22_44_752082/934903580331/tide-tide-twrkflow-eval-v1/automl-forecasting-stage-1-tuner_206416678001573888/tuning_result_output'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_1_tuning_result_artifact_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fff9ed2-1ea5-433c-a20f-d3c5b0bdd7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-tabular-finalizer\n",
      "automl-forecasting-ensemble\n",
      "model-evaluation-forecasting\n",
      "tide-skip-arch-tide-twrkflow-eval-v1-v1\n",
      "get-or-create-model-description\n",
      "feature-transform-engine\n",
      "finalize-eval-quantile-parameters\n",
      "set-optional-inputs\n",
      "calculate-training-parameters\n",
      "table-to-uri\n",
      "condition-2\n",
      "importer\n",
      "string-not-empty\n",
      "model-batch-explanation\n",
      "training-configurator-and-validator\n",
      "model-batch-predict\n",
      "model-upload\n",
      "condition-3\n",
      "condition-4\n",
      "feature-attribution\n",
      "exit-handler-1\n",
      "automl-forecasting-stage-2-tuner\n",
      "model-evaluation-import\n",
      "get-prediction-image-uri\n",
      "split-materialized-data\n",
      "get-predictions-column\n"
     ]
    }
   ],
   "source": [
    "skip_arch_search_pipeline_task_details = job.task_details\n",
    "\n",
    "for task_deets in skip_arch_search_pipeline_task_details:\n",
    "    print(task_deets.task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84540b6f-a2fd-4589-b409-10e93f63fc8a",
   "metadata": {},
   "source": [
    "### Get trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5210e0f-a5eb-40f1-8d46-bc018c99dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tuning stage task\n",
    "stage_2_tuner_task = helpers.get_task_detail(\n",
    "    skip_arch_search_pipeline_task_details, \"automl-forecasting-stage-2-tuner\"\n",
    ")\n",
    "stage_2_tuning_result_artifact_uri = stage_2_tuner_task.outputs[\"tuning_result_output\"].artifacts[0].uri\n",
    "print(f\"stage-2 result URI     : \\n{stage_2_tuning_result_artifact_uri}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13470121-cd4a-4fe3-ae56-5b5002d1b5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage-2 result URI     : \n",
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2909_01_42_271952/934903580331/tide-skip-arch-tide-twrkflow-eval-v1-v1/automl-forecasting-stage-2-tuner_5386119199431065600/tuning_result_output\n",
      "\n",
      "forecasting_mp_model_v2 : \n",
      "<google.cloud.aiplatform.models.Model object at 0x7f639b1c0b20> \n",
      "resource name: projects/934903580331/locations/us-central1/models/3016406796710445056\n"
     ]
    }
   ],
   "source": [
    "# get uploaded model\n",
    "upload_model_task_v2 = helpers.get_task_detail(\n",
    "    skip_arch_search_pipeline_task_details, \"model-upload\"\n",
    ")\n",
    "forecasting_mp_model_v2_artifact = upload_model_task_v2.outputs[\"model\"].artifacts[0]\n",
    "\n",
    "forecasting_mp_model_v2 = aiplatform.Model(forecasting_mp_model_v2_artifact.metadata['resourceName'])\n",
    "print(f\"forecasting_mp_model_v2 : \\n{forecasting_mp_model_v2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91eb65ae-00d3-4253-a1a6-e64c8b0e43cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_id: -6674520602667122688\n",
       "task_name: \"tide-skip-arch-tide-twrkflow-eval-v1-v1\"\n",
       "create_time {\n",
       "  seconds: 1703840910\n",
       "  nanos: 506927000\n",
       "}\n",
       "start_time {\n",
       "  seconds: 1703840911\n",
       "  nanos: 239967000\n",
       "}\n",
       "end_time {\n",
       "  seconds: 1703845862\n",
       "  nanos: 413734000\n",
       "}\n",
       "executor_detail {\n",
       "}\n",
       "state: SUCCEEDED\n",
       "execution {\n",
       "  name: \"projects/934903580331/locations/us-central1/metadataStores/default/executions/15616573050056497927\"\n",
       "  display_name: \"tide-skip-arch-tide-twrkflow-eval-v1-v1\"\n",
       "  state: COMPLETE\n",
       "  etag: \"1703845862230\"\n",
       "  create_time {\n",
       "    seconds: 1703840910\n",
       "    nanos: 962000000\n",
       "  }\n",
       "  update_time {\n",
       "    seconds: 1703845862\n",
       "    nanos: 230000000\n",
       "  }\n",
       "  schema_title: \"system.Run\"\n",
       "  schema_version: \"0.0.1\"\n",
       "  metadata {\n",
       "    fields {\n",
       "      key: \"input:available_at_forecast_columns\"\n",
       "      value {\n",
       "        list_value {\n",
       "          values {\n",
       "            string_value: \"date\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:context_window\"\n",
       "      value {\n",
       "        number_value: 150.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:data_source_bigquery_table_path\"\n",
       "      value {\n",
       "        string_value: \"bq://bigquery-public-data.iowa_liquor_sales_forecasting.2020_sales_train\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:data_source_csv_filenames\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:dataflow_service_account\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:dataflow_subnetwork\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:dataflow_use_public_ips\"\n",
       "      value {\n",
       "        bool_value: true\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:enable_probabilistic_inference\"\n",
       "      value {\n",
       "        bool_value: false\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:encryption_spec_key_name\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluated_examples_bigquery_path\"\n",
       "      value {\n",
       "        string_value: \"bq://hybrid-vertex.tide_twrkflow_eval_v1\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_batch_explain_machine_type\"\n",
       "      value {\n",
       "        string_value: \"n1-highmem-8\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_batch_explain_max_replica_count\"\n",
       "      value {\n",
       "        number_value: 22.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_batch_explain_starting_replica_count\"\n",
       "      value {\n",
       "        number_value: 22.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_batch_predict_machine_type\"\n",
       "      value {\n",
       "        string_value: \"n1-standard-16\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_batch_predict_max_replica_count\"\n",
       "      value {\n",
       "        number_value: 25.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_batch_predict_starting_replica_count\"\n",
       "      value {\n",
       "        number_value: 25.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_dataflow_disk_size_gb\"\n",
       "      value {\n",
       "        number_value: 50.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_dataflow_machine_type\"\n",
       "      value {\n",
       "        string_value: \"n1-standard-16\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_dataflow_max_num_workers\"\n",
       "      value {\n",
       "        number_value: 25.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:evaluation_dataflow_starting_num_workers\"\n",
       "      value {\n",
       "        number_value: 22.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:fast_testing\"\n",
       "      value {\n",
       "        bool_value: false\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:feature_transform_engine_bigquery_staging_full_dataset_id\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:feature_transform_engine_dataflow_disk_size_gb\"\n",
       "      value {\n",
       "        number_value: 40.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:feature_transform_engine_dataflow_machine_type\"\n",
       "      value {\n",
       "        string_value: \"n1-standard-16\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:feature_transform_engine_dataflow_max_num_workers\"\n",
       "      value {\n",
       "        number_value: 10.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:forecast_horizon\"\n",
       "      value {\n",
       "        number_value: 150.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:group_columns\"\n",
       "      value {\n",
       "        null_value: NULL_VALUE\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:group_temporal_total_weight\"\n",
       "      value {\n",
       "        number_value: 0.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:group_total_weight\"\n",
       "      value {\n",
       "        number_value: 0.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:holiday_regions\"\n",
       "      value {\n",
       "        null_value: NULL_VALUE\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:location\"\n",
       "      value {\n",
       "        string_value: \"us-central1\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:model_description\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:model_display_name\"\n",
       "      value {\n",
       "        string_value: \"automl-forecasting-model-upload-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:num_selected_trials\"\n",
       "      value {\n",
       "        number_value: 5.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:optimization_objective\"\n",
       "      value {\n",
       "        string_value: \"minimize-wape-mae\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:predefined_split_key\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:project\"\n",
       "      value {\n",
       "        string_value: \"hybrid-vertex\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:quantiles\"\n",
       "      value {\n",
       "        null_value: NULL_VALUE\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:root_dir\"\n",
       "      value {\n",
       "        string_value: \"gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2909_01_42_271952\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:run_evaluation\"\n",
       "      value {\n",
       "        bool_value: true\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:stage_1_num_parallel_trials\"\n",
       "      value {\n",
       "        number_value: 35.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:stage_1_tuner_worker_pool_specs_override\"\n",
       "      value {\n",
       "        list_value {\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:stage_1_tuning_result_artifact_uri\"\n",
       "      value {\n",
       "        string_value: \"gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2907_22_44_752082/934903580331/tide-tide-twrkflow-eval-v1/automl-forecasting-stage-1-tuner_206416678001573888/tuning_result_output\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:stage_2_num_parallel_trials\"\n",
       "      value {\n",
       "        number_value: 35.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:stage_2_trainer_worker_pool_specs_override\"\n",
       "      value {\n",
       "        list_value {\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:study_spec_parameters_override\"\n",
       "      value {\n",
       "        list_value {\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:target_column\"\n",
       "      value {\n",
       "        string_value: \"sale_dollars\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:temporal_total_weight\"\n",
       "      value {\n",
       "        number_value: 0.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:test_fraction\"\n",
       "      value {\n",
       "        number_value: 0.1\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:time_column\"\n",
       "      value {\n",
       "        string_value: \"date\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:time_series_attribute_columns\"\n",
       "      value {\n",
       "        list_value {\n",
       "          values {\n",
       "            string_value: \"city\"\n",
       "          }\n",
       "          values {\n",
       "            string_value: \"zip_code\"\n",
       "          }\n",
       "          values {\n",
       "            string_value: \"county\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:time_series_identifier_columns\"\n",
       "      value {\n",
       "        list_value {\n",
       "          values {\n",
       "            string_value: \"store_name\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:timestamp_split_key\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:train_budget_milli_node_hours\"\n",
       "      value {\n",
       "        number_value: 250.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:training_fraction\"\n",
       "      value {\n",
       "        number_value: 0.8\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:transformations\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"auto\"\n",
       "            value {\n",
       "              list_value {\n",
       "                values {\n",
       "                  string_value: \"date\"\n",
       "                }\n",
       "                values {\n",
       "                  string_value: \"sale_dollars\"\n",
       "                }\n",
       "                values {\n",
       "                  string_value: \"city\"\n",
       "                }\n",
       "                values {\n",
       "                  string_value: \"zip_code\"\n",
       "                }\n",
       "                values {\n",
       "                  string_value: \"county\"\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"categorical\"\n",
       "            value {\n",
       "              list_value {\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"numeric\"\n",
       "            value {\n",
       "              list_value {\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"text\"\n",
       "            value {\n",
       "              list_value {\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"timestamp\"\n",
       "            value {\n",
       "              list_value {\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:unavailable_at_forecast_columns\"\n",
       "      value {\n",
       "        list_value {\n",
       "          values {\n",
       "            string_value: \"sale_dollars\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:validation_fraction\"\n",
       "      value {\n",
       "        number_value: 0.1\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:weight_column\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:window_max_count\"\n",
       "      value {\n",
       "        number_value: 0.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:window_predefined_column\"\n",
       "      value {\n",
       "        string_value: \"\"\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"input:window_stride_length\"\n",
       "      value {\n",
       "        number_value: 0.0\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"not_presented_inputs\"\n",
       "      value {\n",
       "        list_value {\n",
       "          values {\n",
       "            string_value: \"holiday_regions\"\n",
       "          }\n",
       "          values {\n",
       "            string_value: \"quantiles\"\n",
       "          }\n",
       "          values {\n",
       "            string_value: \"group_columns\"\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"vertex-ai-pipelines-artifact-argument-binding\"\n",
       "      value {\n",
       "        struct_value {\n",
       "          fields {\n",
       "            key: \"output:feature-attribution-feature_attributions\"\n",
       "            value {\n",
       "              list_value {\n",
       "                values {\n",
       "                  string_value: \"projects/934903580331/locations/us-central1/metadataStores/default/artifacts/15670133625162546647\"\n",
       "                }\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "outputs {\n",
       "  key: \"feature-attribution-feature_attributions\"\n",
       "  value {\n",
       "    artifacts {\n",
       "      name: \"projects/934903580331/locations/us-central1/metadataStores/default/artifacts/15670133625162546647\"\n",
       "      display_name: \"feature_attributions\"\n",
       "      uri: \"gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/tide-twrkflow-eval-v1/run-2909_01_42_271952/934903580331/tide-skip-arch-tide-twrkflow-eval-v1-v1/feature-attribution_3865450637751746560/feature_attributions\"\n",
       "      etag: \"1703845862203\"\n",
       "      create_time {\n",
       "        seconds: 1703845508\n",
       "        nanos: 685000000\n",
       "      }\n",
       "      update_time {\n",
       "        seconds: 1703845862\n",
       "        nanos: 203000000\n",
       "      }\n",
       "      state: LIVE\n",
       "      schema_title: \"system.Metrics\"\n",
       "      schema_version: \"0.0.1\"\n",
       "      metadata {\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "pipeline_task_status {\n",
       "  update_time {\n",
       "    seconds: 1703845861\n",
       "    nanos: 981484659\n",
       "  }\n",
       "  state: SUCCEEDED\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get values for stage-2 trials\n",
    "for task_deets in skip_arch_search_pipeline_task_details:\n",
    "    if task_deets.task_name == \"tide-skip-arch-tide-twrkflow-eval-v1-v1\":\n",
    "        # break\n",
    "        stage_2_parallel_trials = task_deets.execution.metadata.get(key=\"input:stage_2_num_parallel_trials\")\n",
    "        stage_2_worker_pool_spec = task_deets.execution.metadata.get(key=\"input:stage_2_trainer_worker_pool_specs_override\")\n",
    "    \n",
    "print(f\"stage_2_parallel_trials  : {stage_2_parallel_trials}\")\n",
    "print(f\"stage_2_worker_pool_spec : {stage_2_worker_pool_spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3b980-d104-4117-b762-f5a8ba77a88a",
   "metadata": {},
   "source": [
    "### Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c5b49fd-7a9b-4294-965d-1b2c30c2ead6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'createTime': '2023-12-29T10:28:31.692046Z',\n",
      " 'displayName': 'Vertex Forecasting pipeline',\n",
      " 'metadata': {'evaluation_dataset_path': ['bq://hybrid-vertex.vertex_feature_transform_engine_staging_us.vertex_ai_fte_split_output_test_staging_id5efc32f2a70e48bbbc24bef6e28b5331'],\n",
      "              'evaluation_dataset_type': 'bigquery',\n",
      "              'pipeline_job_id': '7487788809241755648',\n",
      "              'pipeline_job_resource_name': 'projects/934903580331/locations/us-central1/pipelineJobs/tide-skip-arch-tide-twrkflow-eval-v1-v1'},\n",
      " 'metrics': {'meanAbsoluteError': 4128.132,\n",
      "             'meanAbsolutePercentageError': 405.4942,\n",
      "             'rSquared': 0.5472558,\n",
      "             'rootMeanSquaredError': 9180.089,\n",
      "             'rootMeanSquaredLogError': 0.9531391,\n",
      "             'rootMeanSquaredPercentageError': 5343.9043,\n",
      "             'weightedAbsolutePercentageError': 48.812996},\n",
      " 'metricsSchemaUri': 'gs://google-cloud-aiplatform/schema/modelevaluation/forecasting_metrics_1.0.0.yaml',\n",
      " 'modelExplanation': {'meanAttributions': [{'featureAttributions': {'city': 77.72522828588328,\n",
      "                                                                    'county': 44.59189790698212,\n",
      "                                                                    'date': 422.9841234999592,\n",
      "                                                                    'sale_dollars': 5728.135184951725,\n",
      "                                                                    'zip_code': 13.547329363941682}}]},\n",
      " 'name': 'projects/934903580331/locations/us-central1/models/3016406796710445056@1/evaluations/2429997948310490520'}\n"
     ]
    }
   ],
   "source": [
    "if RUN_EVALUATION:\n",
    "    forecast_EVALS = forecasting_mp_model_v2.list_model_evaluations()\n",
    "\n",
    "    for model_evaluation in forecast_EVALS:\n",
    "        pprint(model_evaluation.to_dict())\n",
    "        \n",
    "else:\n",
    "    print(f\"Model evaluations were set to: {RUN_EVALUATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99ee6208-8f50-4bed-b6ea-7df9996637ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's evaluation metrics from training:\n",
      "\n",
      "metric: rootMeanSquaredPercentageError, value: 5343.9043\n",
      "\n",
      "metric: rootMeanSquaredLogError, value: 0.9531391\n",
      "\n",
      "metric: weightedAbsolutePercentageError, value: 48.812996\n",
      "\n",
      "metric: meanAbsolutePercentageError, value: 405.4942\n",
      "\n",
      "metric: rSquared, value: 0.5472558\n",
      "\n",
      "metric: rootMeanSquaredError, value: 9180.089\n",
      "\n",
      "metric: meanAbsoluteError, value: 4128.132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if RUN_EVALUATION:\n",
    "    # Get evaluations\n",
    "    model_evaluations = forecasting_mp_model_v2.list_model_evaluations()\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    for evaluation in model_evaluations:\n",
    "        evaluation = evaluation.to_dict()\n",
    "        print(\"Model's evaluation metrics from training:\\n\")\n",
    "        metrics = evaluation[\"metrics\"]\n",
    "        for metric in metrics.keys():\n",
    "            print(f\"metric: {metric}, value: {metrics[metric]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df0cf8-0c87-4668-8a60-ad2c24e57294",
   "metadata": {},
   "source": [
    "## (3) TiDE - challenger vs blessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166519b-ba95-4cb0-ac6f-59840906d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import gapic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7dcf1948-bef9-4cc8-8aa8-5b85ec79a3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://google-cloud-aiplatform/schema/modelevaluation/classification_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/forecasting_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/general_text_generation_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/image_object_detection_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/question_answering_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/regression_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/summarization_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/text_extraction_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/text_sentiment_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/video_action_recognition_metrics_1.0.0.yaml\n",
      "gs://google-cloud-aiplatform/schema/modelevaluation/video_object_tracking_metrics_1.0.0.yaml\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://google-cloud-aiplatform/schema/modelevaluation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8635ac-69c8-4e86-8b40-771d22358a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blessed_eval = gapic.ModelEvaluation(\n",
    "    display_name=\"eval\",\n",
    "    metrics_schema_uri=\"gs://google-cloud-aiplatform/schema/modelevaluation/forecasting_metrics_1.0.0.yaml\",\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7e77a-d29f-4740-b3a6-bdc322ea63d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be457b55-48f7-48ea-ab63-31377fff2d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4cd9ae-3cbb-4289-954b-f87401bf6565",
   "metadata": {},
   "source": [
    "## (4) TiDE - comparing pipeline runs\n",
    "\n",
    "* see similar [GitHub example](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/comparing_pipeline_runs.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b85925-793a-4ac5-bab9-53146e1e1e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runs = [\n",
    "    {\"max_depth\": 4, \"learning_rate\": 0.2, \"boost_rounds\": 10},\n",
    "    {\"max_depth\": 5, \"learning_rate\": 0.3, \"boost_rounds\": 20},\n",
    "    {\"max_depth\": 3, \"learning_rate\": 0.1, \"boost_rounds\": 30},\n",
    "    {\"max_depth\": 6, \"learning_rate\": 0.5, \"boost_rounds\": 40},\n",
    "    {\"max_depth\": 5, \"learning_rate\": 0.4, \"boost_rounds\": 30},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c67341-f40a-4fc9-aa93-2f05f9421b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, run in enumerate(runs):\n",
    "\n",
    "    job = vertex_ai.PipelineJob(\n",
    "        display_name=f\"{EXPERIMENT_NAME}-pipeline-run-{i}\",\n",
    "        template_path=\"pipeline.json\",\n",
    "        pipeline_root=PIPELINE_URI,\n",
    "        parameter_values={\n",
    "            \"train_uri\": TRAIN_URI,\n",
    "            \"label_uri\": LABEL_URI,\n",
    "            \"model_uri\": MODEL_URI,\n",
    "            **run,\n",
    "        },\n",
    "    )\n",
    "    job.submit(experiment=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981af642-0c6b-4b74-bc0a-c002b876c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see state of all pipelineJob\n",
    "vertex_ai.get_experiment_df(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e494aa-9a82-4a44-ae08-dc2cdc745702",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01e80a-880c-4e46-a265-2f4753ccabe8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch Prediction job\n",
    "\n",
    "> You can enable the batch explain feature by simply setting `generate_explanation=True` in the `batch_predict` API.\n",
    "\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49b0b550-3818-4a3c-a5d1-b87bf98ad38e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGQUERY_DATASET_NAME : forecast_refresh_v1\n",
      "PRED_BQ_OUTPUT_DS_URI : bq://hybrid-vertex.forecast_refresh_v1\n"
     ]
    }
   ],
   "source": [
    "BIGQUERY_DATASET_NAME = f\"{PREFIX}\".replace(\"-\",\"_\")\n",
    "\n",
    "PRED_BQ_OUTPUT_DS_URI = f\"bq://{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\"\n",
    "\n",
    "print(f\"BIGQUERY_DATASET_NAME : {BIGQUERY_DATASET_NAME}\")\n",
    "print(f\"PRED_BQ_OUTPUT_DS_URI : {PRED_BQ_OUTPUT_DS_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7c3b4bb-7f21-4c1b-b84c-abbfbb7e7105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hybrid-vertex:forecast_refresh_v1\n"
     ]
    }
   ],
   "source": [
    "ds = bigquery.Dataset(f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\")\n",
    "ds.location = BQ_LOCATION\n",
    "ds = bq_client.create_dataset(dataset = ds, exists_ok = True)\n",
    "\n",
    "print(ds.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757e206-dd48-4eed-8e27-06094b042266",
   "metadata": {},
   "source": [
    "### confirm predict dataset.table URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3cae4607-1b19-4a84-9448-a1f96e00d129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_PUBLIC_DS_NAME = \"bigquery-public-data.iowa_liquor_sales_forecasting\"\n",
    "\n",
    "# tables = bq_client.list_tables(PUBLIC_DS_NAME)\n",
    "# # tables\n",
    "\n",
    "# print(\"Tables contained in '{}':\".format(PUBLIC_DS_NAME))\n",
    "# for table in tables:\n",
    "#     print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2285c87f-5428-471e-ba19-d7bdfb128b43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ_PUBLIC_PRED_TABLE_SRC: bigquery-public-data.iowa_liquor_sales_forecasting.2021_sales_predict\n"
     ]
    }
   ],
   "source": [
    "BQ_PUBLIC_PRED_TABLE_SRC = f\"{BQ_PUBLIC_DS_NAME}.2021_sales_predict\"\n",
    "\n",
    "print(f\"BQ_PUBLIC_PRED_TABLE_SRC: {BQ_PUBLIC_PRED_TABLE_SRC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b39f1-51b4-44d2-b026-d41d0361d643",
   "metadata": {},
   "source": [
    "**bigquery_destination_prefix**\n",
    "* The BigQuery URI to a project or table, up to 2000 characters long.\n",
    "* when only the project is specified, the Dataset and Table is created.\n",
    "* When the full table reference is specified, the Dataset *must* exist and table *must not exist*. \n",
    "* Accepted forms: \n",
    "\n",
    "> `bq://projectId` or `bq://projectId.bqDatasetId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3bbe4d56-8f96-401b-8f6e-92d072809c60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION_BQ_TABLE_URI  : hybrid-vertex.forecast_refresh_v1.iowa_2021_sales_predict\n",
      "PREDICTION_BQ_TABLE_PATH : bq://hybrid-vertex.forecast_refresh_v1.iowa_2021_sales_predict\n"
     ]
    }
   ],
   "source": [
    "BQ_PRED_TABLE_NAME       = \"iowa_2021_sales_predict\"\n",
    "PREDICTION_BQ_TABLE_URI  = f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}.{BQ_PRED_TABLE_NAME}\"\n",
    "PREDICTION_BQ_TABLE_PATH = f\"bq://{PROJECT_ID}.{BIGQUERY_DATASET_NAME}.{BQ_PRED_TABLE_NAME}\"\n",
    "\n",
    "print(f\"PREDICTION_BQ_TABLE_URI  : {PREDICTION_BQ_TABLE_URI}\")\n",
    "print(f\"PREDICTION_BQ_TABLE_PATH : {PREDICTION_BQ_TABLE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db2a532c-908e-4106-8163-991d02d4fbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query = f\"\"\"\n",
    "# CREATE OR REPLACE TABLE `{PREDICTION_BQ_TABLE_URI}` AS\n",
    "#    SELECT * \n",
    "#     FROM `{BQ_PUBLIC_PRED_TABLE_SRC}`\n",
    "# \"\"\"\n",
    "\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86f612-aa52-4769-9d24-b1dd1f9bc2ca",
   "metadata": {},
   "source": [
    "If needed, copy/paste above query in BQ console to debug. Execute cell below to run query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64448e20-2fb1-4ba3-9769-8e9144c28652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# job = bq_client.query(query)\n",
    "# job.result()\n",
    "# (job.ended-job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba92481d-0e49-4f87-b842-c8705c172d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch pred for model : automl-forecasting-model-upload-7426145789342121984-5745633113434750976\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running batch pred for model : {forecasting_mp_model.display_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a84e73-cbbb-4832-bc8a-0508a1c4d657",
   "metadata": {},
   "source": [
    "### Choosing machine_type and replica count\n",
    "\n",
    "**CPU-only machines**\n",
    "* To get the best throughput, choose the smallest machine types (e.g. 2 cores, although RAM requirements vary) with as many replicas as can be kept full.\n",
    "* Scaling horizontally by increasing the number of replicas improves throughput in a linear and predictable way. \n",
    "* Scaling vertically by using bigger machine types does not always improve throughput linearly.\n",
    "\n",
    "For cost-effectiveness, choose replica count such that the batch prediction job runs for at least 10 minutes. \n",
    "* This is because you are billed per replica node hour, which includes the approximately 5 minutes it takes for each replica to start up. \n",
    "* It is not cost-effective to process for only a few seconds and then shut down.\n",
    "\n",
    "The variables you need to calculate the number of replicas to use are as follows:\n",
    "\n",
    "* **N**: The number of batches in the job. For example, 1 million instances / 100 batch size = 10,000 batches.\n",
    "* **T**: desired time for the batch prediction job. For example, 10 minutes.\n",
    "* **Tb**: time in seconds it takes for a replica to process a single batch. For example, 1 second per batch on a 2-core machine type.\n",
    "\n",
    "Then the number of replicas is **N** / (**T** * (**60** / **Tb**)). \n",
    "\n",
    "> 10,000 batches / (10 minutes * (60 / 1s)) ~= 17 replicas.\n",
    "\n",
    "See [docs](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#aiplatform_batch_predict_custom_trained-python_vertex_ai_sdk) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c553bf9-73ab-45f0-a2c0-76e3dd991eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE           = \"n2-standard-4\"\n",
    "ACCELERATOR_COUNT      = None\n",
    "ACCELERATOR_TYPE       = None\n",
    "STARTING_REPLICA_COUNT = 4\n",
    "MAX_REPLICA_COUNT      = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "431943f7-1f0b-4a25-a72f-5a59a5b0a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "<google.cloud.aiplatform.jobs.BatchPredictionJob object at 0x7f1adc5e0400> is waiting for upstream dependencies to complete.\n",
      "BatchPredictionJob created. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/6385977484176785408?project=934903580331\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = forecasting_mp_model.batch_predict(\n",
    "    job_display_name=f\"{PREFIX}-bpj\",\n",
    "    bigquery_source=PREDICTION_BQ_TABLE_PATH,\n",
    "    instances_format=\"bigquery\",\n",
    "    bigquery_destination_prefix=PRED_BQ_OUTPUT_DS_URI, # \"projectId.bqDatasetId.bqTableId\" (?)\n",
    "    predictions_format=\"bigquery\",\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    starting_replica_count=STARTING_REPLICA_COUNT,\n",
    "    max_replica_count=MAX_REPLICA_COUNT,\n",
    "    generate_explanation=False,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_prediction_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be825ba9-0ee6-4980-a87b-3231d2b46bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/batchPredictionJobs/6385977484176785408',\n",
       " 'displayName': 'forecast-refresh-v1-bpj',\n",
       " 'model': 'projects/934903580331/locations/us-central1/models/5976397651799703552',\n",
       " 'inputConfig': {'instancesFormat': 'bigquery',\n",
       "  'bigquerySource': {'inputUri': 'bq://hybrid-vertex.vertex_feature_transform_engine_us.dlt_output_table_6385977484176785408'}},\n",
       " 'outputConfig': {'predictionsFormat': 'bigquery',\n",
       "  'bigqueryDestination': {'outputUri': 'bq://hybrid-vertex.forecast_refresh_v1'}},\n",
       " 'dedicatedResources': {'machineSpec': {'machineType': 'n2-standard-4'},\n",
       "  'startingReplicaCount': 4,\n",
       "  'maxReplicaCount': 12},\n",
       " 'manualBatchTuningParameters': {},\n",
       " 'outputInfo': {'bigqueryOutputDataset': 'bq://hybrid-vertex.forecast_refresh_v1',\n",
       "  'bigqueryOutputTable': 'predictions_2023_12_28T16_02_01_117Z_466'},\n",
       " 'state': 'JOB_STATE_SUCCEEDED',\n",
       " 'completionStats': {'successfulCount': '1721',\n",
       "  'successfulForecastPointCount': '5869'},\n",
       " 'createTime': '2023-12-29T00:02:01.307123Z',\n",
       " 'startTime': '2023-12-29T00:02:01.354353Z',\n",
       " 'endTime': '2023-12-29T00:15:28Z',\n",
       " 'updateTime': '2023-12-29T00:17:45.260963Z',\n",
       " 'modelVersionId': '1'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BPJ_OUTPUT_DICT = batch_prediction_job.to_dict()\n",
    "\n",
    "trained_forecast = aiplatform.Model(BPJ_OUTPUT_DICT['model'])\n",
    "\n",
    "BPJ_OUTPUT_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3c51c2a-3d4e-44f0-802f-49a272c1edfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bq://hybrid-vertex.forecast_refresh_v1.predictions_2023_12_28T16_02_01_117Z_466\n",
      "batch_predict_bq_output_uri : bq://hybrid-vertex.forecast_refresh_v1.predictions_2023_12_28T16_02_01_117Z_466\n",
      "cleaned_bq_output_uri       : hybrid-vertex.forecast_refresh_v1.predictions_2023_12_28T16_02_01_117Z_466\n"
     ]
    }
   ],
   "source": [
    "batch_predict_bq_output_uri = \"{}.{}\".format(\n",
    "    batch_prediction_job.output_info.bigquery_output_dataset,\n",
    "    batch_prediction_job.output_info.bigquery_output_table\n",
    ")\n",
    "\n",
    "def _sanitize_bq_uri(bq_uri):\n",
    "    if bq_uri.startswith(\"bq://\"):\n",
    "        bq_uri = bq_uri[5:]\n",
    "    \n",
    "    return bq_uri.replace(\":\", \".\")\n",
    "\n",
    "cleaned_bq_output_uri = _sanitize_bq_uri(\n",
    "    batch_predict_bq_output_uri\n",
    ")\n",
    "\n",
    "print(batch_predict_bq_output_uri)\n",
    "print(f\"batch_predict_bq_output_uri : {batch_predict_bq_output_uri}\")\n",
    "print(f\"cleaned_bq_output_uri       : {cleaned_bq_output_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f168959-7c79-428c-b663-09f9847c3638",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### View the batch prediction results\n",
    "\n",
    "**Working with quantiles / prediction intervals**\n",
    "* see this guide for details: [Example batch prediction output for a quantile-loss optimized model](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/forecasting-batch-predictions#example_batch_prediction_output_for_a_quantile-loss_optimized_model)\n",
    "* `predicted_sales.quantile_values` will give the quantiles, i.e. `[0.1, 0.3, 0.5, 0.7, 0.9]`\n",
    "* `predicted_sales.quantile_predictions` will be an array of the same length with matching predictions\n",
    "* There is also a field `predicted_sales.value` which is just the prediction for the 0.5 quantile (median)\n",
    "\n",
    "\n",
    "**Different statistics can be estimated from the quantiles, including statistics that minimize:**\n",
    "\n",
    "* RMSE (weighted mean of quantile values)\n",
    "* MAPE (median weighted by 1/value)\n",
    "* MAE (median)\n",
    "\n",
    "Use the BigQuery Python client to query the destination table and return results as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7720b671-ce58-4fd0-b9c3-c3dc32e638f9",
   "metadata": {},
   "source": [
    "#### IF Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d446b984-68b4-49c9-86e5-742cbe563fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Quantiles        : 3\n",
      "Quantiles             : [0.25, 0.5, 0.9]\n",
      "cleaned_quantile_list : ['25', '50', '90']\n"
     ]
    }
   ],
   "source": [
    "def _get_quantile_strings(quantile_list):\n",
    "    \n",
    "    cleaned_list = []\n",
    "    \n",
    "    for ele in quantile_list:\n",
    "        if str(ele).startswith(\"0.\"):\n",
    "            # cleaned_list.append(str(round(ele, 2)).replace(\"0.\",\"\"))\n",
    "            cleaned_list.append(('{0:.2f}'.format(ele)).replace(\"0.\",\"\"))\n",
    "                \n",
    "        if str(ele).startswith(\".\"):\n",
    "            # cleaned_list.append(str(round(ele, 2)).replace(\".\",\"\"))\n",
    "            cleaned_list.append(('{0:.2f}'.format(ele)).replace(\"0.\",\"\"))\n",
    "    \n",
    "    return cleaned_list\n",
    "\n",
    "cleaned_quantile_list = _get_quantile_strings(QUANTILES)\n",
    "\n",
    "print(f\"# of Quantiles        : {len(QUANTILES)}\")\n",
    "print(f\"Quantiles             : {QUANTILES}\")\n",
    "print(f\"cleaned_quantile_list : {cleaned_quantile_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49d17b3b-eee5-4995-8c8b-21304e8e81e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT\n",
      " *EXCEPT(predicted_sale_dollars),\n",
      " predicted_sale_dollars.value AS predicted_sales_mean,\n",
      "  predicted_sale_dollars.quantile_predictions[OFFSET(0)] AS predicted_sale_dollars_p25, predicted_sale_dollars.quantile_predictions[OFFSET(1)] AS predicted_sale_dollars_p50, predicted_sale_dollars.quantile_predictions[OFFSET(2)] AS predicted_sale_dollars_p90,\n",
      "FROM\n",
      " `hybrid-vertex.forecast_refresh_v1.predictions_2023_12_28T16_02_01_117Z_466`\n",
      " LIMIT 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quantile_string = \"\"\n",
    "\n",
    "# for i in range(0, len(cleaned_quantile_list)):\n",
    "#     quantile_string += f\" predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET({i})] AS predicted_{TARGET_COLUMN}_p{cleaned_quantile_list[i]},\"\n",
    "    \n",
    "# # quantile_string\n",
    "\n",
    "# TARGET_COLUMN = \"sale_dollars\"\n",
    "\n",
    "# query = f\"\"\"\n",
    "# SELECT\n",
    "#  *EXCEPT(predicted_{TARGET_COLUMN}),\n",
    "#  predicted_{TARGET_COLUMN}.value AS predicted_sales_mean,\n",
    "#  {quantile_string}\n",
    "# FROM\n",
    "#  `{cleaned_bq_output_uri}`\n",
    "#  LIMIT 100\n",
    "# \"\"\"\n",
    "# print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9edb0613-cb7e-459c-a68a-827142a73285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT\n",
      " *EXCEPT(predicted_sale_dollars),\n",
      " predicted_sale_dollars.value AS predicted_sales_mean,\n",
      " predicted_sale_dollars.quantile_predictions[OFFSET(0)] AS predicted_sale_dollars_p25,\n",
      " predicted_sale_dollars.quantile_predictions[OFFSET(1)] AS predicted_sale_dollars_p50,\n",
      " predicted_sale_dollars.quantile_predictions[OFFSET(2)] AS predicted_sale_dollars_p90,\n",
      "FROM\n",
      " `hybrid-vertex.forecast_refresh_v1.predictions_2023_12_28T16_02_01_117Z_466`\n",
      " LIMIT 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLUMN = \"sale_dollars\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    " *EXCEPT(predicted_{TARGET_COLUMN}),\n",
    " predicted_{TARGET_COLUMN}.value AS predicted_sales_mean,\n",
    " predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET(0)] AS predicted_{TARGET_COLUMN}_p25,\n",
    " predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET(1)] AS predicted_{TARGET_COLUMN}_p50,\n",
    " predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET(2)] AS predicted_{TARGET_COLUMN}_p90,\n",
    "FROM\n",
    " `{cleaned_bq_output_uri}`\n",
    " LIMIT 100\n",
    "\"\"\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738007a-9035-470a-b40f-611beedff0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs_eval['date'] = qs_eval[\"date\"].astype(\"datetime64[ns]\")\n",
    "# qs_eval['predicted_sales_mean'].dtype\n",
    "\n",
    "qs_eval = bq_client.query(query).to_dataframe()\n",
    "\n",
    "qs_eval['date'] = qs_eval[\"date\"].astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2606240-371d-4005-beb8-ba7af9a16a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th>predicted_on_date</th>\n",
       "      <th>sale_dollars</th>\n",
       "      <th>store_name</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>predicted_sales_mean</th>\n",
       "      <th>predicted_sale_dollars_p25</th>\n",
       "      <th>predicted_sale_dollars_p50</th>\n",
       "      <th>predicted_sale_dollars_p90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altoona</td>\n",
       "      <td>POLK</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Super Stop Liquor and Wine / Altoona</td>\n",
       "      <td>50009.0</td>\n",
       "      <td>3989.0</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>3994.0</td>\n",
       "      <td>6723.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Altoona</td>\n",
       "      <td>POLK</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Super Stop Liquor and Wine / Altoona</td>\n",
       "      <td>50009.0</td>\n",
       "      <td>3833.0</td>\n",
       "      <td>2431.0</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>7467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altoona</td>\n",
       "      <td>POLK</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Super Stop Liquor and Wine / Altoona</td>\n",
       "      <td>50009.0</td>\n",
       "      <td>4191.5</td>\n",
       "      <td>2522.0</td>\n",
       "      <td>4192.0</td>\n",
       "      <td>7512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city county       date predicted_on_date  sale_dollars  \\\n",
       "0  Altoona   POLK 2021-04-01        2021-04-01           NaN   \n",
       "1  Altoona   POLK 2021-04-09        2021-04-01           NaN   \n",
       "2  Altoona   POLK 2021-04-16        2021-04-01           NaN   \n",
       "\n",
       "                             store_name zip_code  predicted_sales_mean  \\\n",
       "0  Super Stop Liquor and Wine / Altoona  50009.0                3989.0   \n",
       "1  Super Stop Liquor and Wine / Altoona  50009.0                3833.0   \n",
       "2  Super Stop Liquor and Wine / Altoona  50009.0                4191.5   \n",
       "\n",
       "   predicted_sale_dollars_p25  predicted_sale_dollars_p50  \\\n",
       "0                      2169.0                      3994.0   \n",
       "1                      2431.0                      3842.0   \n",
       "2                      2522.0                      4192.0   \n",
       "\n",
       "   predicted_sale_dollars_p90  \n",
       "0                      6723.0  \n",
       "1                      7467.0  \n",
       "2                      7512.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_eval.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389de638-00fb-4139-87a7-43b5830e1a79",
   "metadata": {},
   "source": [
    "## Model evaluation pipeline\n",
    "* see [Model evaluation components](https://cloud.google.com/vertex-ai/docs/pipelines/model-evaluation-component#models) for details\n",
    "* `model.evaluate()` - API [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/models.py#L5143)\n",
    "  * only \"regression\" and \"classifcation\" available at this time\n",
    "  \n",
    "\n",
    "**The pipeline uses the following components:**\n",
    "\n",
    "`GetVertexModelOp`\n",
    "* Gets a Vertex AI Model artifact\n",
    "\n",
    "`EvaluationDataSamplerOp` \n",
    "* Randomly downsamples an input dataset to a specified size for computing Vertex Explainable AI feature attributions for AutoML Tabular and custom models\n",
    "* Creates a Dataflow job with Apache Beam to downsample the dataset\n",
    "\n",
    "`TargetFieldDataRemoverOp` \n",
    "* Removes the target field from the input dataset for supporting unstructured AutoML models and custom models for Vertex AI batch prediction\n",
    "\n",
    "`ModelBatchPredictOp`\n",
    "* Creates a Vertex AI batch prediction job and waits for it to complete\n",
    "* [documentation](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-2.0.0/api/v1/batch_predict_job.html)\n",
    "\n",
    "`ModelEvaluationFeatureAttributionOp` \n",
    "* Compute feature attribution on a trained model’s batch explanation results\n",
    "* Creates a Dataflow job with Apache Beam and TFMA to compute feature attributions\n",
    "\n",
    "`ModelImportEvaluationOp`: \n",
    "* Imports a model evaluation artifact to an existing Vertex AI model with `ModelService.ImportModelEvaluation`\n",
    "\n",
    "\n",
    "`ModelEvaluationForecastingOp`\n",
    "* Computes a `google.ForecastingMetrics` Artifact, containing evaluation metrics given a model's prediction results.\n",
    "* Creates a Dataflow job with Apache Beam and TFMA to compute evaluation metrics.\n",
    "* Supports point forecasting and quantile forecasting for tabular data.\n",
    "* check here for [src code](https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/v1/model_evaluation/forecasting_component.py#L27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd83ae3f-422c-4ea7-813b-df39f285dc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "# from kfp.v2 import compiler, dsl\n",
    "# from kfp.v2.dsl import (\n",
    "\n",
    "from kfp import compiler, dsl\n",
    "\n",
    "from kfp.dsl import (\n",
    "    component, \n",
    "    pipeline, \n",
    "    Artifact, \n",
    "    # ClassificationMetrics, \n",
    "    Input, \n",
    "    Output, \n",
    "    Model, \n",
    "    Metrics\n",
    ")\n",
    "\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "590ffde2-eea0-4dc2-abcc-633995697ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_PIPE_DIR: gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/forecast-refresh-v1-v4/evals/tide-qs-v5\n",
      "PIPELINE_NAME: eval-tide-qs-v5-forecast-refresh-v1\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_VERSION=\"v5\"\n",
    "\n",
    "EVAL_SUBDIR = \"evals\"\n",
    "PIPELINE_TAG = f'tide-qs-{PIPELINE_VERSION}'\n",
    "\n",
    "EVAL_PIPE_DIR = f\"{BUCKET_URI}/automl_forecasting_pipeline/{EXPERIMENT_NAME}/{EVAL_SUBDIR}/{PIPELINE_TAG}\"\n",
    "\n",
    "PIPELINE_NAME = f'eval-{PIPELINE_TAG}-{PREFIX}'.replace('_', '-') # EXPERIMENT_NAME\n",
    "print(f'EVAL_PIPE_DIR: {EVAL_PIPE_DIR}')\n",
    "print(f\"PIPELINE_NAME: {PIPELINE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1abc1c-e4e6-4e4b-bb58-1c09f8802a27",
   "metadata": {},
   "source": [
    "### Create custom component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5daf205-eeae-485b-8fd6-99e9695758e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bfd815ac-0757-4ce7-b29f-6cbffea64d99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/create_bq_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/create_bq_dataset.py\n",
    "\n",
    "import kfp\n",
    "from typing import NamedTuple\n",
    "from kfp.dsl import (\n",
    "    # Artifact, \n",
    "    # Dataset, \n",
    "    # Input, InputPath, \n",
    "    # Model, Output, OutputPath, \n",
    "    component, \n",
    "    Metrics\n",
    ")\n",
    "\n",
    "@component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==3.14.1'],\n",
    ")\n",
    "def create_bq_dataset(\n",
    "    project: str,\n",
    "    # vertex_dataset: str,\n",
    "    new_bq_dataset: str,\n",
    "    bq_location: str\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('bq_dataset_name', str),\n",
    "    ('bq_dataset_uri', str),\n",
    "]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    bq_client = bigquery.Client(project=project, location=bq_location) # bq_location)\n",
    "    (\n",
    "      bq_client.query(f'CREATE SCHEMA IF NOT EXISTS `{project}.{new_bq_dataset}`')\n",
    "      .result()\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        f'{new_bq_dataset}',\n",
    "        f'bq://{project}.{new_bq_dataset}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c4faa-ec87-46db-b245-0aff6301a845",
   "metadata": {},
   "source": [
    "## Build pipeline\n",
    "\n",
    "* see [examples](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/b67cccb91a7382b1adeae913509eb8ea6881d59b/notebooks/official/model_evaluation/automl_tabular_regression_model_evaluation.ipynb#L777) for inspiration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "27aa4e33-fe0f-40e2-b147-f993304ee6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from vertex_components import lookup_model, model_batch_predict\n",
    "# from google_cloud_pipeline_components.v1.batch_predict_job.component import model_batch_predict\n",
    "\n",
    "# ?GetVertexModelOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b63d41e-c4f4-4273-bf20-4639f785a15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import create_bq_dataset\n",
    "\n",
    "from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "# from google_cloud_pipeline_components.v1.batch_predict_job.component import model_batch_predict\n",
    "\n",
    "from google_cloud_pipeline_components.v1.model_evaluation import ModelEvaluationForecastingOp\n",
    "\n",
    "from google_cloud_pipeline_components.preview.model_evaluation import ModelEvaluationFeatureAttributionOp\n",
    "\n",
    "from google_cloud_pipeline_components._implementation.model import GetVertexModelOp\n",
    "from google_cloud_pipeline_components._implementation.model_evaluation import (\n",
    "    ModelImportEvaluationOp, \n",
    "    TargetFieldDataRemoverOp, \n",
    "    EvaluationDataSamplerOp,\n",
    ")\n",
    "\n",
    "@dsl.pipeline(\n",
    "  name=PIPELINE_NAME\n",
    ")\n",
    "def pipeline(\n",
    "    vertex_project: str,\n",
    "    location: str,\n",
    "    bq_location: str,\n",
    "    version: str,\n",
    "    new_bq_dataset_name: str,\n",
    "    batch_predict_machine_type: str,\n",
    "    # gcs_root_dir: str,\n",
    "    target_column: str,\n",
    "    model_name: str,\n",
    "    # new_bq_dataset: str,\n",
    "    batch_predict_instances_format: str,\n",
    "    prediction_dataset_bq_path: str,\n",
    "):\n",
    "    \"\"\"An eval pipeline.\"\"\"\n",
    "\n",
    "    # # create BQ dataset\n",
    "    # create_dataset_op = (\n",
    "    #   create_bq_dataset.create_bq_dataset(\n",
    "    #       project=vertex_project,\n",
    "    #       # vertex_dataset=\"tmp\",\n",
    "    #       new_bq_dataset=new_bq_dataset_name,\n",
    "    #       bq_location=bq_location\n",
    "    #   )\n",
    "    # )\n",
    "    \n",
    "    get_model_task = GetVertexModelOp(model_name=model_name)\n",
    "\n",
    "    # ======================================\n",
    "    # Model Eval Workflow\n",
    "    # ======================================\n",
    "\n",
    "    # Run Data-sampling task\n",
    "    data_sampler_task = (\n",
    "        EvaluationDataSamplerOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            # root_dir=gcs_root_dir,\n",
    "            bigquery_source_uri=prediction_dataset_bq_path,\n",
    "            instances_format=batch_predict_instances_format,\n",
    "            sample_size=2000,\n",
    "            # dataflow_subnetwork=None,\n",
    "            dataflow_use_public_ips=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Run Target field-removal task\n",
    "    target_remover_task = (\n",
    "        TargetFieldDataRemoverOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            # root_dir=gcs_root_dir,\n",
    "            bigquery_source_uri=data_sampler_task.outputs[\"bigquery_output_table\"],\n",
    "            instances_format=batch_predict_instances_format,\n",
    "            target_field_name=target_column,\n",
    "            # dataflow_subnetwork=None,\n",
    "            dataflow_use_public_ips=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Run Batch Explanations\n",
    "    batch_predict_task = (\n",
    "        ModelBatchPredictOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            model=get_model_task.outputs['model'],\n",
    "            job_display_name=f\"bpj-eval-{PIPELINE_TAG}\",\n",
    "            bigquery_source_input_uri=target_remover_task.outputs[\"bigquery_output_table\"],\n",
    "            bigquery_destination_output_uri=f'bq://{vertex_project}', # create_dataset_op.outputs[\"bq_dataset_uri\"], #f'bq://{vertex_project}',\n",
    "            instances_format=batch_predict_instances_format,\n",
    "            predictions_format=batch_predict_instances_format,\n",
    "            machine_type=batch_predict_machine_type,\n",
    "            starting_replica_count=4,\n",
    "            max_replica_count=10,\n",
    "            # Set the explanation parameters\n",
    "            generate_explanation=False,\n",
    "            # explanation_parameters=batch_predict_explanation_parameters,\n",
    "            # explanation_metadata=batch_predict_explanation_metadata,\n",
    "            # service_account=service_account\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # # Run Batch Explanations\n",
    "    # batch_predict_task = (\n",
    "    #     model_batch_predict(\n",
    "    #         project=vertex_project,\n",
    "    #         location=location,\n",
    "    #         model=get_model_task.outputs['model'],\n",
    "    #         job_display_name=f\"bpj-eval-{PIPELINE_TAG}\",\n",
    "    #         bigquery_source_input_uri=target_remover_task.outputs[\"bigquery_output_table\"],\n",
    "    #         bigquery_destination_output_uri=f'bq://{vertex_project}',   #create_dataset_op.outputs[\"bq_dataset_uri\"],\n",
    "    #         instances_format=batch_predict_instances_format,\n",
    "    #         predictions_format=batch_predict_instances_format,\n",
    "    #         machine_type=batch_predict_machine_type,\n",
    "    #         # starting_replica_count=4,\n",
    "    #         max_replica_count=10,\n",
    "    #         # Set the explanation parameters\n",
    "    #         generate_explanation=False,\n",
    "    #         # explanation_parameters=batch_predict_explanation_parameters,\n",
    "    #         # explanation_metadata=batch_predict_explanation_metadata,\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # Run evaluation based on prediction type and feature attribution component.\n",
    "    # After, import the model evaluations to the Vertex model.\n",
    "    model_eval_task = (\n",
    "        ModelEvaluationForecastingOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            target_field_name=target_column,\n",
    "            predictions_bigquery_source=batch_predict_task.outputs[\"bigquery_output_table\"],\n",
    "            predictions_format=batch_predict_instances_format,\n",
    "            model=get_model_task.outputs['model'],\n",
    "            # prediction_score_column=\"prediction.scores\",\n",
    "            forecasting_type=\"quantile\", #\"point\",\n",
    "            forecasting_quantiles=[0.10, 0.25, 0.5, 0.75, .90],\n",
    "            ground_truth_bigquery_source=data_sampler_task.outputs[\"bigquery_output_table\"],\n",
    "            ground_truth_format=batch_predict_instances_format,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Import the evaluation results to the model resource\n",
    "    model_import_task = (\n",
    "        ModelImportEvaluationOp(\n",
    "            problem_type=\"forecasting\",\n",
    "            forecasting_metrics=model_eval_task.outputs[\"evaluation_metrics\"],\n",
    "            # feature_attributions=feature_attribution_task.outputs[\"feature_attributions\"],\n",
    "            model=get_model_task.outputs['model'],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "61fa69c0-9405-426a-aa49-81323864f210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIPELINE_JSON_SPEC_LOCAL = \"custom_pipeline_spec.json\"\n",
    "\n",
    "! rm -f $PIPELINE_JSON_SPEC_LOCAL\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, \n",
    "    package_path=PIPELINE_JSON_SPEC_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a8dda4c4-6b0b-4aaf-a887-a184f193aa70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://custom_pipeline_spec.json [Content-Type=application/json]...\n",
      "/ [1 files][ 66.5 KiB/ 66.5 KiB]                                                \n",
      "Operation completed over 1 objects/66.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $PIPELINE_JSON_SPEC_LOCAL $EVAL_PIPE_DIR/$PIPELINE_JSON_SPEC_LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9c5b435-b94f-4337-9f74-11df96f2816f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_LOCATION = \"us-central1\"\n",
    "\n",
    "# BPJ_OUTPUT_DICT = {}\n",
    "# BPJ_OUTPUT_DICT['model'] = 'projects/934903580331/locations/us-central1/models/1896206758146211840'\n",
    "\n",
    "# PREDICTION_DATASET_BQ_PATH = f\"bq://{PROJECT_ID}.a_us_forecast_data_repo.2021_sales_predict\"\n",
    "PREDICTION_DATASET_BQ_PATH = f\"bq://{PROJECT_ID}.a_central_forecast_data_ds.2021_sales_predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f68d56e7-dcb7-4e8c-a550-2f5bcfec3e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_VERSION           : v5\n",
      "BQ_LOCATION                : us-central1\n",
      "target_column              : sale_dollars\n",
      "PREDICTION_DATASET_BQ_PATH : bq://hybrid-vertex.a_central_forecast_data_ds.2021_sales_predict\n",
      "BPJ_OUTPUT_DICT['model']   : projects/934903580331/locations/us-central1/models/5976397651799703552\n"
     ]
    }
   ],
   "source": [
    "print(f\"PIPELINE_VERSION           : {PIPELINE_VERSION}\")\n",
    "print(f\"BQ_LOCATION                : {BQ_LOCATION}\")\n",
    "print(f\"target_column              : {target_column}\")\n",
    "print(f\"PREDICTION_DATASET_BQ_PATH : {PREDICTION_DATASET_BQ_PATH}\")\n",
    "print(f\"BPJ_OUTPUT_DICT['model']   : {BPJ_OUTPUT_DICT['model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ebc2a870-98a3-473e-a736-451fa59b2990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bq://hybrid-vertex.a_central_forecast_data_ds.2021_sales_predict'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTION_DATASET_BQ_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2663282-5716-4d3c-bfe4-e23b265eacb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315?project=934903580331\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/934903580331/locations/us-central1/pipelineJobs/eval-tide-qs-v5-forecast-refresh-v1-20231229062315 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=f\"{EVAL_PIPE_DIR}/{PIPELINE_JSON_SPEC_LOCAL}\",\n",
    "    pipeline_root=EVAL_PIPE_DIR,\n",
    "    enable_caching=True,\n",
    "    failure_policy='fast', # slow | fast\n",
    "    parameter_values={\n",
    "        'vertex_project': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'version': VERSION,\n",
    "        \"bq_location\": BQ_LOCATION,\n",
    "        \"batch_predict_instances_format\": 'bigquery',\n",
    "        \"target_column\": target_column,\n",
    "        \"model_name\": BPJ_OUTPUT_DICT['model'],\n",
    "        \"batch_predict_machine_type\": \"n2-standard-4\",\n",
    "        # \"gcs_root_dir\": EVAL_PIPE_DIR,\n",
    "        # \"data_source_dataset\": f'forecast_eval_{VERSION}_us',\n",
    "        \"prediction_dataset_bq_path\" : PREDICTION_DATASET_BQ_PATH,\n",
    "        \"new_bq_dataset_name\" : f\"a_fresh_eval_{PIPELINE_VERSION}_central\"\n",
    "    }   \n",
    ")\n",
    "\n",
    "job.run(\n",
    "    sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    "    # network=f'projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c611a-0b11-4085-82bb-5f9e892b35de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Archive v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed137db-c09f-414d-bea4-d3efa27467a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vertex forecasting model trained in the pipeline: https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/prob-infer-forecast-refresh-v1-v1?project=hybrid-vertex'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forecasting_mp_model = aiplatform.Model(BPJ_OUTPUT_DICT['model'])\n",
    "forecasting_mp_model.description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5027f1f2-50cf-447e-85d4-6bcac75093e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bq://bigquery-public-data:iowa_liquor_sales_forecasting.2021_sales_predict'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTION_DATASET_BQ_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821840d9-c20d-4830-bfc5-f6c29b1752bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BQ dataset for source data source\n",
    "DATA_SOURCE_DATASET = f'forecast_eval_{PIPELINE_VERSION}_us'\n",
    "\n",
    "bigquery_source_uri = PREDICTION_DATASET_BQ_PATH\n",
    "\n",
    "# 'bq://hybrid-vertex.forecast_refresh_v1'\n",
    "\n",
    "\"batch_predict_instances_format\": 'bigquery',\n",
    "\n",
    "parameter_values={\n",
    "    'vertex_project': PROJECT_ID,\n",
    "    'location': LOCATION,\n",
    "    'version': PIPELINE_VERSION,\n",
    "    \"batch_predict_instances_format\": 'bigquery',\n",
    "    \"target_column\": target_column,\n",
    "    \"model_name\": BPJ_OUTPUT_DICT['model'],\n",
    "    \"batch_predict_machine_type\": \"n1-standard-4\",\n",
    "    \"gcs_root_dir\": XXXXXX,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4724dade-07c2-45f2-8a1c-f4b650755a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/934903580331/locations/us-central1/models/1896206758146211840'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BPJ_OUTPUT_DICT['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997befdd-a2fd-4b65-a48a-2eb3a2113b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bd9c7-dd3a-4161-85d6-5703226cc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RUN_EVALUATION:\n",
    "#     forecast_EVALS = forecasting_mp_model.list_model_evaluations()\n",
    "    \n",
    "#     for model_evaluation in forecast_EVALS:\n",
    "#         pprint(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15bf095d-32f7-4987-af58-5e66d7618155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get evaluations\n",
    "model_evaluations = trained_forecast.list_model_evaluations()\n",
    "\n",
    "# Print the evaluation metrics\n",
    "for evaluation in model_evaluations:\n",
    "    evaluation = evaluation.to_dict()\n",
    "    print(\"Model's evaluation metrics from training:\\n\")\n",
    "    metrics = evaluation[\"metrics\"]\n",
    "    for metric in metrics.keys():\n",
    "        print(f\"metric: {metric}, value: {metrics[metric]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25696115-3ff1-45ac-897a-e149a3d7a649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qs_eval['date'] = qs_eval[\"date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "qs_eval['predicted_sales_mean'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c586e62-b65e-47cf-ae45-769b96d09ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the results as a dataframe\n",
    "# df_output = batch_prediction_job.iter_outputs(bq_max_results=1000).to_dataframe()\n",
    "\n",
    "# Convert the dates to the datetime64 datatype\n",
    "# df_output[\"date\"] = df_output[\"date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "# Extract the predicted sales and convert to floats\n",
    "# df_output[\"pred_median\"] = (\n",
    "#     df_output[\"predicted_sales\"].apply(lambda x: x[\"value\"]).astype(float)\n",
    "# )\n",
    "\n",
    "# df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32e0fe-90a1-4fc8-958a-3e73aa590998",
   "metadata": {},
   "source": [
    "### Compare predictions vs ground truth\n",
    "\n",
    "> TODO\n",
    "\n",
    "Plot the predicted values vs the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef62f44-2d5b-41f5-9b0d-a0eed0165047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a shared dataframe to plot predictions vs ground truth\n",
    "df_output[\"sales_comparison\"] = df_output[\"predicted_sales\"]\n",
    "df_output[\"is_ground_truth\"] = False\n",
    "df_test_horizon_actual[\"sales_comparison\"] = df_test_horizon_actual[\"sales\"]\n",
    "df_test_horizon_actual[\"is_ground_truth\"] = True\n",
    "df_prediction_comparison = pd.concat([df_output, df_test_horizon_actual])\n",
    "\n",
    "# Plot sales\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(24, 12)\n",
    "\n",
    "sns.relplot(\n",
    "    data=df_prediction_comparison,\n",
    "    x=\"date\",\n",
    "    y=\"sales_comparison\",\n",
    "    hue=\"product_at_store\",\n",
    "    style=\"store\",\n",
    "    row=\"is_ground_truth\",\n",
    "    height=5,\n",
    "    aspect=4,\n",
    "    kind=\"line\",\n",
    "    ci=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc865dea-382d-4dfc-bff0-5fc7d6f5a95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1deaf341-4781-45fc-b475-e9bc4111557a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Archive v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91cbd6d-0839-47bb-bc2d-286de010919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_forecast = aiplatform.Model(\n",
    "#     model_name=BPJ_OUTPUT_DICT['model']\n",
    "# )\n",
    "# my_evaluation_job = trained_forecast.evaluate(\n",
    "#     prediction_type=\"classification\",\n",
    "#     target_field_name=\"type\",\n",
    "#     data_source_uris=[\"gs://sdk-model-eval/my-prediction-data.csv\"],\n",
    "#     staging_bucket=\"gs://my-staging-bucket/eval_pipeline_root\",\n",
    "# )\n",
    "# my_evaluation_job.wait()\n",
    "# my_evaluation = my_evaluation_job.get_model_evaluation()\n",
    "# my_evaluation.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc736d6-e6a0-4228-a063-33242a0ba53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from google_cloud_pipeline_components.aiplatform import ModelBatchPredictOp\n",
    "# from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "\n",
    "# from google_cloud_pipeline_components.v1.model_evaluation import ModelEvaluationForecastingOp\n",
    "\n",
    "# from google_cloud_pipeline_components.preview.model_evaluation import ModelEvaluationFeatureAttributionOp\n",
    "\n",
    "# from google_cloud_pipeline_components._implementation.model_evaluation import (ModelImportEvaluationOp, TargetFieldDataRemoverOp)\n",
    "\n",
    "# preview.model_evaluation.ModelEvaluationFeatureAttributionOp\n",
    "# from google_cloud_pipeline_components.experimental.evaluation import (\n",
    "#     # EvaluationDataSamplerOp, \n",
    "#     # GetVertexModelOp,\n",
    "#     # ModelEvaluationForecastingOp, \n",
    "#     # ModelEvaluationFeatureAttributionOp,\n",
    "#     # ModelImportEvaluationOp, \n",
    "#     # TargetFieldDataRemoverOp\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
