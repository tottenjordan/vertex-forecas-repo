{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35dc312e-aa9e-4d09-944f-100eb7ee6509",
   "metadata": {},
   "source": [
    "# Probabilistic Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd63e1-a2e6-44d8-a956-ee602430fbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install {USER_FLAG} google-cloud-aiplatform kfp google-cloud-pipeline-components --upgrade\n",
    "# !pip3 install --no-cache-dir {USER_FLAG} PyYAML==5.3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f338bf-70d6-4464-89dd-f87a45d99cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa145e15-4650-4e2e-a5a8-ea9f71816ef1",
   "metadata": {},
   "source": [
    "## Load notebook config\n",
    "\n",
    "> use the prefix defined in 00-env-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb269c2c-5697-4f9e-ab5b-2bd9f0868ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_NEW_ASSETS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae3b82-a0f7-41ed-9e2c-3a0552974d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"              # TODO\n",
    "PREFIX         = f'forecast-refresh-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1368cb3-2cdf-4571-9281-c847cead0318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# ! gcloud config set project $PROJECT_ID\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-gcs'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd1173-e7ec-45d2-ac4f-ef6f35f1e18e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For a list of available model metrics, go here:\n",
    "!gsutil ls $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d40790-c76b-4473-8b94-836131bd8cb4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adde7be5-33b5-4ea0-befe-96c895a42225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = f\"{PREFIX}-v1\"\n",
    "\n",
    "print(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986ccbd-7a47-4a01-a673-3fc0c706192d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import json\n",
    "import datetime\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from google.cloud import aiplatform, storage, bigquery\n",
    "\n",
    "# from google_cloud_pipeline_components.types.artifact_types import VertexDataset\n",
    "from google_cloud_pipeline_components.preview.automl.forecasting import \\\n",
    "    utils as automl_forecasting_utils\n",
    "\n",
    "\n",
    "# Construct a BigQuery client object.\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "aiplatform.init(experiment=EXPERIMENT_NAME, project=PROJECT_ID, location=REGION)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65b389-d25a-4724-b2ea-c8c7cb3b88c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CREATE_NEW_ASSETS:\n",
    "    ds = bigquery.Dataset(f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\")\n",
    "    ds.location = BQ_LOCATION\n",
    "    ds = bqclient.create_dataset(dataset = ds, exists_ok = False)\n",
    "    # print(ds.full_dataset_id)\n",
    "else:\n",
    "    ds = bigquery.Dataset(f\"{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\")\n",
    "    \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45f81e-9371-469e-97a7-6f747454df2e",
   "metadata": {},
   "source": [
    "## prepare train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe6f627-9f46-42c8-8699-1c7b8472e1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2106_14_34_399161\n"
     ]
    }
   ],
   "source": [
    "# Dataflow's fully qualified subnetwork name, when empty the default subnetwork will be used.\n",
    "dataflow_subnetwork = None \n",
    "\n",
    "# Specifies whether Dataflow workers use public IP addresses.\n",
    "dataflow_use_public_ips = True\n",
    "\n",
    "# NOW = datetime.datetime.now().strftime(\"%d %H:%M:%S.%f\").replace(\" \",\"\").replace(\":\",\"_\").replace(\".\",\"_\")\n",
    "NOW = '2106_14_34_399161' # tmp\n",
    "\n",
    "print(NOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2165270-2e51-4246-90f6-9b2173fb59c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR              = gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/forecast-refresh-v1-v1/run-2106_14_34_399161\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR                      = f\"{BUCKET_URI}/automl_forecasting_pipeline/{EXPERIMENT_NAME}/run-{NOW}\"\n",
    "time_column                   = \"date\"\n",
    "time_series_identifier_column = \"store_name\"\n",
    "target_column                 = \"sale_dollars\"\n",
    "data_source_csv_filenames     = None\n",
    "\n",
    "print(f\"ROOT_DIR              = {ROOT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aed5e93-24b2-4161-8666-da43fa78a872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available_at_forecast_columns    = ['date']\n",
      "unavailable_at_forecast_columns  = ['sale_dollars']\n",
      "time_series_attribute_columns    = ['city', 'zip_code', 'county']\n"
     ]
    }
   ],
   "source": [
    "data_source_bigquery_table_path = (\n",
    "    \"bq://bigquery-public-data.iowa_liquor_sales_forecasting.2020_sales_train\"\n",
    ")\n",
    "\n",
    "training_fraction = 0.8\n",
    "validation_fraction = 0.1\n",
    "test_fraction = 0.1\n",
    "\n",
    "predefined_split_key = None\n",
    "if predefined_split_key:\n",
    "    training_fraction = None\n",
    "    validation_fraction = None\n",
    "    test_fraction = None\n",
    "\n",
    "weight_column = None\n",
    "\n",
    "features = [\n",
    "    time_column,\n",
    "    target_column,\n",
    "    \"city\",\n",
    "    \"zip_code\",\n",
    "    \"county\",\n",
    "]\n",
    "\n",
    "available_at_forecast_columns = [time_column]\n",
    "unavailable_at_forecast_columns = [target_column]\n",
    "time_series_attribute_columns = [\"city\", \"zip_code\", \"county\"]\n",
    "\n",
    "forecast_horizon = 150\n",
    "context_window = 150\n",
    "\n",
    "print(f\"available_at_forecast_columns    = {available_at_forecast_columns}\")\n",
    "print(f\"unavailable_at_forecast_columns  = {unavailable_at_forecast_columns}\")\n",
    "print(f\"time_series_attribute_columns    = {time_series_attribute_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff50d5c-1bef-4f95-92ba-a5877d360460",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformations       = {'auto': ['date', 'sale_dollars', 'city', 'zip_code', 'county'], 'numeric': [], 'categorical': [], 'text': [], 'timestamp': []}\n",
      "\n",
      "TRANSFORM_CONFIG_PATH = gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/run-28ec73a7-646e-420b-b883-2aa16ea2e518/transform_config_40ac07bd-c92b-4914-beda-18a382062acd.json\n"
     ]
    }
   ],
   "source": [
    "# transformations = helpers.generate_auto_transformation(features)\n",
    "transformations = helpers.generate_transformation(auto_column_names=features)\n",
    "\n",
    "# TRANSFORM_CONFIG_PATH = f\"{ROOT_DIR}/transform_config_{NOW}.json\"\n",
    "TRANSFORM_CONFIG_PATH = \"gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/run-28ec73a7-646e-420b-b883-2aa16ea2e518/transform_config_40ac07bd-c92b-4914-beda-18a382062acd.json\"\n",
    "\n",
    "print(f\"transformations       = {transformations}\\n\")\n",
    "print(f\"TRANSFORM_CONFIG_PATH = {TRANSFORM_CONFIG_PATH}\")\n",
    "\n",
    "# helpers.write_to_gcs(TRANSFORM_CONFIG_PATH, json.dumps(transformations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ae7f8b-da1e-419c-b50a-17a69db9436e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/\n",
      "gs://forecast-refresh-v1-hybrid-vertex-gcs/config/\n"
     ]
    }
   ],
   "source": [
    "# For a list of available model metrics, go here:\n",
    "!gsutil ls $BUCKET_URI/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca7d3f-7120-4f9c-9a69-eecd0aa3a307",
   "metadata": {},
   "source": [
    "# Probabilistic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d5c8289-e747-4905-aa05-f2fd0db54eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID = prob-infer-forecast-refresh-v1-v1\n"
     ]
    }
   ],
   "source": [
    "# Number of weak models in the final ensemble model.\n",
    "num_selected_trials = 5\n",
    "train_budget_milli_node_hours = 500  # 30 minutes\n",
    "\n",
    "optimization_objective = \"minimize-quantile-loss\"\n",
    "\n",
    "RUN_EVALUATION = False\n",
    "\n",
    "JOB_ID = f\"prob-infer-{EXPERIMENT_NAME}\"\n",
    "print(f\"JOB_ID = {JOB_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa5a824e-8e1a-40c3-8473-967e8264a398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/934903580331/locations/us-central1/pipelineJobs/prob-infer-forecast-refresh-v1-v1\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/934903580331/locations/us-central1/pipelineJobs/prob-infer-forecast-refresh-v1-v1')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/prob-infer-forecast-refresh-v1-v1?project=934903580331\n",
      "Associating projects/934903580331/locations/us-central1/pipelineJobs/prob-infer-forecast-refresh-v1-v1 to Experiment: forecast-refresh-v1-v1\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    template_path,\n",
    "    parameter_values,\n",
    ") = automl_forecasting_utils.get_time_series_dense_encoder_forecasting_pipeline_and_parameters(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    root_dir=ROOT_DIR,\n",
    "    target_column=target_column,\n",
    "    optimization_objective=optimization_objective,\n",
    "    transformations=transformations,\n",
    "    train_budget_milli_node_hours=train_budget_milli_node_hours,\n",
    "    data_source_csv_filenames=data_source_csv_filenames,\n",
    "    data_source_bigquery_table_path=data_source_bigquery_table_path,\n",
    "    weight_column=weight_column,\n",
    "    predefined_split_key=predefined_split_key,\n",
    "    training_fraction=training_fraction,\n",
    "    validation_fraction=validation_fraction,\n",
    "    test_fraction=test_fraction,\n",
    "    num_selected_trials=num_selected_trials,\n",
    "    time_column=time_column,\n",
    "    time_series_identifier_columns=[time_series_identifier_column],\n",
    "    time_series_attribute_columns=time_series_attribute_columns,\n",
    "    available_at_forecast_columns=available_at_forecast_columns,\n",
    "    unavailable_at_forecast_columns=unavailable_at_forecast_columns,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    context_window=context_window,\n",
    "    dataflow_subnetwork=dataflow_subnetwork,\n",
    "    dataflow_use_public_ips=dataflow_use_public_ips,\n",
    "    run_evaluation=RUN_EVALUATION,                          # set True to eval on test/valid set\n",
    "    # evaluated_examples_bigquery_path=f'bq://{PROJECT_ID}.eval',\n",
    "    enable_probabilistic_inference=True,\n",
    "    # quantile forecast\n",
    "    quantiles=[0.25, 0.5, 0.9],\n",
    ")\n",
    "\n",
    "# job_id = \"tide-forecasting-probabilistic-inference-{}\".format(uuid.uuid4())\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=JOB_ID,\n",
    "    location=REGION,  # launches the pipeline job in the specified region\n",
    "    template_path=template_path,\n",
    "    job_id=JOB_ID,\n",
    "    pipeline_root=ROOT_DIR,\n",
    "    parameter_values=parameter_values,\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "# job.run(sync=False,experiment=EXPERIMENT_NAME)\n",
    "job.submit(\n",
    "    experiment=EXPERIMENT_NAME,\n",
    "    # sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa5ff12-cec7-48ef-a76e-d040d2188093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-tabular-finalizer\n",
      "condition-5\n",
      "split-materialized-data\n",
      "automl-forecasting-stage-1-tuner\n",
      "condition-4\n",
      "set-optional-inputs\n",
      "get-prediction-image-uri-2\n",
      "training-configurator-and-validator\n",
      "prob-infer-forecast-refresh-v1-v1\n",
      "model-upload-2\n",
      "calculate-training-parameters-2\n",
      "feature-transform-engine\n",
      "automl-forecasting-ensemble-2\n",
      "condition-2\n",
      "exit-handler-1\n",
      "get-or-create-model-description-2\n",
      "string-not-empty\n"
     ]
    }
   ],
   "source": [
    "pipeline_task_details = job.task_details\n",
    "\n",
    "for task_deets in pipeline_task_details:\n",
    "    print(task_deets.task_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01e80a-880c-4e46-a265-2f4753ccabe8",
   "metadata": {},
   "source": [
    "# Batch Prediction job\n",
    "\n",
    "> You can enable the batch explain feature by simply setting `generate_explanation=True` in the `batch_predict` API.\n",
    "\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49b0b550-3818-4a3c-a5d1-b87bf98ad38e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forecast_refresh_v1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BIGQUERY_DATASET_NAME = PREFIX.replace(\"-\",\"_\")\n",
    "\n",
    "# ds = bigquery.Dataset(f\"{PROJECT_ID}.{PREFIX_TEMP}\")\n",
    "# ds.location = BQ_LOCATION\n",
    "# ds = bq_client.create_dataset(dataset = ds, exists_ok = False)\n",
    "\n",
    "# print(ds.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026ff0c-8890-48b0-a7cf-0dee2f2b8988",
   "metadata": {},
   "source": [
    "### get trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85adeefd-0ad1-47e7-b735-0a49402ae2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_1_tuning_result_artifact_uri: gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/forecast-refresh-v1-v1/run-2106_14_34_399161/934903580331/prob-infer-forecast-refresh-v1-v1/automl-forecasting-stage-1-tuner_-3853266124770639872/tuning_result_output\n",
      "forecasting_mp_model: <google.cloud.aiplatform.models.Model object at 0x7f70006955a0> \n",
      "resource name: projects/934903580331/locations/us-central1/models/1896206758146211840\n"
     ]
    }
   ],
   "source": [
    "stage_1_tuner_task = helpers.get_task_detail(\n",
    "    pipeline_task_details, \"automl-forecasting-stage-1-tuner\"\n",
    ")\n",
    "stage_1_tuning_result_artifact_uri = (\n",
    "    stage_1_tuner_task.outputs[\"tuning_result_output\"].artifacts[0].uri\n",
    ")\n",
    "print(f\"stage_1_tuning_result_artifact_uri: {stage_1_tuning_result_artifact_uri}\")\n",
    "\n",
    "# get uploaded model\n",
    "upload_model_task = helpers.get_task_detail(\n",
    "    pipeline_task_details, \"model-upload-2\"\n",
    ")\n",
    "\n",
    "forecasting_mp_model_artifact = (\n",
    "    upload_model_task.outputs[\"model\"].artifacts[0]\n",
    ")\n",
    "\n",
    "forecasting_mp_model = aiplatform.Model(forecasting_mp_model_artifact.metadata['resourceName'])\n",
    "print(f\"forecasting_mp_model: {forecasting_mp_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757e206-dd48-4eed-8e27-06094b042266",
   "metadata": {},
   "source": [
    "### confirm predict dataset.table URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cae4607-1b19-4a84-9448-a1f96e00d129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'bigquery-public-data.iowa_liquor_sales_forecasting':\n",
      "bigquery-public-data.iowa_liquor_sales_forecasting.2020_sales_train\n",
      "bigquery-public-data.iowa_liquor_sales_forecasting.2021_sales_predict\n"
     ]
    }
   ],
   "source": [
    "public_ds_name = \"bigquery-public-data.iowa_liquor_sales_forecasting\"\n",
    "\n",
    "# tables = bq_client.list_tables(public_ds_name)\n",
    "# # tables\n",
    "\n",
    "# print(\"Tables contained in '{}':\".format(public_ds_name))\n",
    "# for table in tables:\n",
    "#     print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b39f1-51b4-44d2-b026-d41d0361d643",
   "metadata": {},
   "source": [
    "**bigquery_destination_prefix**\n",
    "* The BigQuery URI to a project or table, up to 2000 characters long.\n",
    "* when only the project is specified, the Dataset and Table is created.\n",
    "* When the full table reference is specified, the Dataset *must* exist and table *must not exist*. \n",
    "* Accepted forms: \n",
    "\n",
    "> `bq://projectId` or `bq://projectId.bqDatasetId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba92481d-0e49-4f87-b842-c8705c172d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Batch prediction for model: automl-forecasting-model-upload-2748858509155106816-1911341398263595008\n",
      "batch_predict_bq_output_uri_prefix: bq://hybrid-vertex.forecast_refresh_v1\n"
     ]
    }
   ],
   "source": [
    "batch_predict_bq_output_uri_prefix = f\"bq://{PROJECT_ID}.{BIGQUERY_DATASET_NAME}\" #.prob_eval_{VERSION}\"\n",
    "\n",
    "PREDICTION_DATASET_BQ_PATH = (\n",
    "    \"bq://bigquery-public-data:iowa_liquor_sales_forecasting.2021_sales_predict\"\n",
    ")\n",
    "\n",
    "print(f\"Running Batch prediction for model: {forecasting_mp_model.display_name}\")\n",
    "print(f\"batch_predict_bq_output_uri_prefix: {batch_predict_bq_output_uri_prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a84e73-cbbb-4832-bc8a-0508a1c4d657",
   "metadata": {},
   "source": [
    "### Choosing machine_type and replica count\n",
    "\n",
    "**CPU-only machines**\n",
    "* To get the best throughput, choose the smallest machine types (e.g. 2 cores, although RAM requirements vary) with as many replicas as can be kept full.\n",
    "* Scaling horizontally by increasing the number of replicas improves throughput in a linear and predictable way. \n",
    "* Scaling vertically by using bigger machine types does not always improve throughput linearly.\n",
    "\n",
    "For cost-effectiveness, choose replica count such that the batch prediction job runs for at least 10 minutes. \n",
    "* This is because you are billed per replica node hour, which includes the approximately 5 minutes it takes for each replica to start up. \n",
    "* It is not cost-effective to process for only a few seconds and then shut down.\n",
    "\n",
    "The variables you need to calculate the number of replicas to use are as follows:\n",
    "\n",
    "* **N**: The number of batches in the job. For example, 1 million instances / 100 batch size = 10,000 batches.\n",
    "* **T**: desired time for the batch prediction job. For example, 10 minutes.\n",
    "* **Tb**: time in seconds it takes for a replica to process a single batch. For example, 1 second per batch on a 2-core machine type.\n",
    "\n",
    "Then the number of replicas is **N** / (**T** * (**60** / **Tb**)). \n",
    "\n",
    "> 10,000 batches / (10 minutes * (60 / 1s)) ~= 17 replicas.\n",
    "\n",
    "See [docs](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#aiplatform_batch_predict_custom_trained-python_vertex_ai_sdk) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c553bf9-73ab-45f0-a2c0-76e3dd991eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE           = \"n2-standard-4\"\n",
    "ACCELERATOR_COUNT      = None\n",
    "ACCELERATOR_TYPE       = None\n",
    "STARTING_REPLICA_COUNT = 4\n",
    "MAX_REPLICA_COUNT      = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "431943f7-1f0b-4a25-a72f-5a59a5b0a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.jobs.BatchPredictionJob object at 0x7f6ffbb29300> is waiting for upstream dependencies to complete.\n",
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/4541316380896526336?project=934903580331\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = forecasting_mp_model.batch_predict(\n",
    "    job_display_name=f\"{PREFIX}-bpj\",\n",
    "    bigquery_source=PREDICTION_DATASET_BQ_PATH,\n",
    "    instances_format=\"bigquery\",\n",
    "    bigquery_destination_prefix=batch_predict_bq_output_uri_prefix, # \"projectId.bqDatasetId.bqTableId\" (?)\n",
    "    predictions_format=\"bigquery\",\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_count=ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    starting_replica_count=STARTING_REPLICA_COUNT,\n",
    "    max_replica_count=MAX_REPLICA_COUNT,\n",
    "    generate_explanation=False,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(batch_prediction_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be825ba9-0ee6-4980-a87b-3231d2b46bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/934903580331/locations/us-central1/batchPredictionJobs/4541316380896526336', 'displayName': 'forecast-refresh-v1-bpj', 'model': 'projects/934903580331/locations/us-central1/models/1896206758146211840', 'inputConfig': {'instancesFormat': 'bigquery', 'bigquerySource': {'inputUri': 'bq://hybrid-vertex.vertex_feature_transform_engine_us.dlt_output_table_4541316380896526336'}}, 'outputConfig': {'predictionsFormat': 'bigquery', 'bigqueryDestination': {'outputUri': 'bq://hybrid-vertex.forecast_refresh_v1'}}, 'dedicatedResources': {'machineSpec': {'machineType': 'n2-standard-4'}, 'startingReplicaCount': 4, 'maxReplicaCount': 12}, 'manualBatchTuningParameters': {}, 'outputInfo': {'bigqueryOutputDataset': 'bq://hybrid-vertex.forecast_refresh_v1', 'bigqueryOutputTable': 'predictions_2023_12_21T04_39_15_619Z_334'}, 'state': 'JOB_STATE_SUCCEEDED', 'completionStats': {'successfulCount': '1721', 'successfulForecastPointCount': '5869'}, 'createTime': '2023-12-21T12:39:15.654897Z', 'startTime': '2023-12-21T12:39:15.694888Z', 'endTime': '2023-12-21T12:54:00Z', 'updateTime': '2023-12-21T12:55:29.922189Z', 'modelVersionId': '1'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BPJ_OUTPUT_DICT = batch_prediction_job.to_dict()\n",
    "\n",
    "trained_forecast = aiplatform.Model(BPJ_OUTPUT_DICT['model'])\n",
    "\n",
    "BPJ_OUTPUT_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3c51c2a-3d4e-44f0-802f-49a272c1edfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bq://hybrid-vertex.forecast_refresh_v1.predictions_2023_12_21T04_39_15_619Z_334\n",
      "batch_predict_bq_output_uri : bq://hybrid-vertex.forecast_refresh_v1.predictions_2023_12_21T04_39_15_619Z_334\n",
      "cleaned_bq_output_uri       : hybrid-vertex.forecast_refresh_v1.predictions_2023_12_21T04_39_15_619Z_334\n"
     ]
    }
   ],
   "source": [
    "batch_predict_bq_output_uri = \"{}.{}\".format(\n",
    "    batch_prediction_job.output_info.bigquery_output_dataset,\n",
    "    batch_prediction_job.output_info.bigquery_output_table\n",
    ")\n",
    "\n",
    "def _sanitize_bq_uri(bq_uri):\n",
    "    if bq_uri.startswith(\"bq://\"):\n",
    "        bq_uri = bq_uri[5:]\n",
    "    \n",
    "    return bq_uri.replace(\":\", \".\")\n",
    "\n",
    "cleaned_bq_output_uri = _sanitize_bq_uri(\n",
    "    batch_predict_bq_output_uri\n",
    ")\n",
    "\n",
    "print(batch_predict_bq_output_uri)\n",
    "print(f\"batch_predict_bq_output_uri : {batch_predict_bq_output_uri}\")\n",
    "print(f\"cleaned_bq_output_uri       : {cleaned_bq_output_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f168959-7c79-428c-b663-09f9847c3638",
   "metadata": {},
   "source": [
    "## View the batch prediction results\n",
    "\n",
    "**Working with quantiles / prediction intervals**\n",
    "* see this guide for details: [Example batch prediction output for a quantile-loss optimized model](https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/forecasting-batch-predictions#example_batch_prediction_output_for_a_quantile-loss_optimized_model)\n",
    "* `predicted_sales.quantile_values` will give the quantiles, i.e. `[0.1, 0.3, 0.5, 0.7, 0.9]`\n",
    "* `predicted_sales.quantile_predictions` will be an array of the same length with matching predictions\n",
    "* There is also a field `predicted_sales.value` which is just the prediction for the 0.5 quantile (median)\n",
    "\n",
    "\n",
    "**Different statistics can be estimated from the quantiles, including statistics that minimize:**\n",
    "\n",
    "* RMSE (weighted mean of quantile values)\n",
    "* MAPE (median weighted by 1/value)\n",
    "* MAE (median)\n",
    "\n",
    "Use the BigQuery Python client to query the destination table and return results as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb0613-cb7e-459c-a68a-827142a73285",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = \"sale_dollars\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    " *EXCEPT(predicted_{TARGET_COLUMN}),\n",
    " predicted_{TARGET_COLUMN}.value AS predicted_sales_mean,\n",
    " predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET(0)] AS predicted_{TARGET_COLUMN}_p25,\n",
    " predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET(1)] AS predicted_{TARGET_COLUMN}_p50,\n",
    " predicted_{TARGET_COLUMN}.quantile_predictions[OFFSET(2)] AS predicted_{TARGET_COLUMN}_p90,\n",
    "FROM\n",
    " `{cleaned_bq_output_uri}`\n",
    " LIMIT 100\n",
    "\"\"\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2606240-371d-4005-beb8-ba7af9a16a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs_eval['date'] = qs_eval[\"date\"].astype(\"datetime64[ns]\")\n",
    "# qs_eval['predicted_sales_mean'].dtype\n",
    "\n",
    "qs_eval = bq_client.query(query).to_dataframe()\n",
    "\n",
    "qs_eval['date'] = qs_eval[\"date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "qs_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389de638-00fb-4139-87a7-43b5830e1a79",
   "metadata": {},
   "source": [
    "# Model evaluation pipeline\n",
    "* see [Model evaluation components](https://cloud.google.com/vertex-ai/docs/pipelines/model-evaluation-component#models) for details\n",
    "* `model.evaluate()` - API [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/models.py#L5143)\n",
    "  * only \"regression\" and \"classifcation\" available at this time\n",
    "  \n",
    "\n",
    "**The pipeline uses the following components:**\n",
    "\n",
    "`GetVertexModelOp`\n",
    "* Gets a Vertex AI Model artifact\n",
    "\n",
    "`EvaluationDataSamplerOp` \n",
    "* Randomly downsamples an input dataset to a specified size for computing Vertex Explainable AI feature attributions for AutoML Tabular and custom models\n",
    "* Creates a Dataflow job with Apache Beam to downsample the dataset\n",
    "\n",
    "`TargetFieldDataRemoverOp` \n",
    "* Removes the target field from the input dataset for supporting unstructured AutoML models and custom models for Vertex AI batch prediction\n",
    "\n",
    "`ModelBatchPredictOp`\n",
    "* Creates a Vertex AI batch prediction job and waits for it to complete\n",
    "\n",
    "`ModelEvaluationFeatureAttributionOp` \n",
    "* Compute feature attribution on a trained model’s batch explanation results\n",
    "* Creates a Dataflow job with Apache Beam and TFMA to compute feature attributions\n",
    "\n",
    "`ModelImportEvaluationOp`: \n",
    "* Imports a model evaluation artifact to an existing Vertex AI model with `ModelService.ImportModelEvaluation`\n",
    "\n",
    "\n",
    "`ModelEvaluationForecastingOp`\n",
    "* Computes a `google.ForecastingMetrics` Artifact, containing evaluation metrics given a model's prediction results.\n",
    "* Creates a Dataflow job with Apache Beam and TFMA to compute evaluation metrics.\n",
    "* Supports point forecasting and quantile forecasting for tabular data.\n",
    "* check here for [src code](https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/v1/model_evaluation/forecasting_component.py#L27https://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/v1/model_evaluation/forecasting_component.py#L27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd83ae3f-422c-4ea7-813b-df39f285dc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "# from kfp.v2 import compiler, dsl\n",
    "# from kfp.v2.dsl import (\n",
    "\n",
    "from kfp import compiler, dsl\n",
    "\n",
    "from kfp.dsl import (\n",
    "    component, \n",
    "    pipeline, \n",
    "    Artifact, \n",
    "    # ClassificationMetrics, \n",
    "    Input, \n",
    "    Output, \n",
    "    Model, \n",
    "    Metrics\n",
    ")\n",
    "\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "590ffde2-eea0-4dc2-abcc-633995697ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL_PIPE_DIR: gs://forecast-refresh-v1-hybrid-vertex-gcs/automl_forecasting_pipeline/forecast-refresh-v1-v1/evals/tide-quantiles\n",
      "PIPELINE_NAME: eval-tide-quantiles-forecast-refresh-v1-v1\n"
     ]
    }
   ],
   "source": [
    "EVAL_SUBDIR = \"evals\"\n",
    "PIPELINE_TAG = 'tide-qs'\n",
    "EVAL_PIPE_DIR = f\"{BUCKET_URI}/automl_forecasting_pipeline/{EXPERIMENT_NAME}/{EVAL_SUBDIR}/{PIPELINE_TAG}\"\n",
    "print(f'EVAL_PIPE_DIR: {EVAL_PIPE_DIR}')\n",
    "\n",
    "PIPELINE_NAME = f'eval-{PIPELINE_TAG}-{EXPERIMENT_NAME}'.replace('_', '-')\n",
    "print(f\"PIPELINE_NAME: {PIPELINE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1abc1c-e4e6-4e4b-bb58-1c09f8802a27",
   "metadata": {},
   "source": [
    "### Create custom component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5daf205-eeae-485b-8fd6-99e9695758e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/jt_repo/vertex-forecas-repo/05-tabular-workflows\n"
     ]
    }
   ],
   "source": [
    "# REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bfd815ac-0757-4ce7-b29f-6cbffea64d99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/create_bq_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/create_bq_dataset.py\n",
    "\n",
    "import kfp\n",
    "from typing import NamedTuple\n",
    "from kfp.dsl import (\n",
    "    # Artifact, \n",
    "    # Dataset, \n",
    "    # Input, InputPath, \n",
    "    # Model, Output, OutputPath, \n",
    "    component, \n",
    "    Metrics\n",
    ")\n",
    "\n",
    "@component(\n",
    "  base_image='python:3.9',\n",
    "  packages_to_install=['google-cloud-bigquery==3.14.1'],\n",
    ")\n",
    "def create_bq_dataset(\n",
    "    project: str,\n",
    "    # vertex_dataset: str,\n",
    "    new_bq_dataset: str,\n",
    "    bq_location: str\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('bq_dataset_name', str),\n",
    "    ('bq_dataset_uri', str),\n",
    "]):\n",
    "    \n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    bq_client = bigquery.Client(project=project, location='US') # bq_location)\n",
    "    (\n",
    "      bq_client.query(f'CREATE SCHEMA IF NOT EXISTS `{project}.{new_bq_dataset}`')\n",
    "      .result()\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        f'{new_bq_dataset}',\n",
    "        f'bq://{project}:{new_bq_dataset}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b63d41e-c4f4-4273-bf20-4639f785a15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import create_bq_dataset\n",
    "\n",
    "from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "from google_cloud_pipeline_components.v1.model_evaluation import ModelEvaluationForecastingOp\n",
    "\n",
    "from google_cloud_pipeline_components.preview.model_evaluation import ModelEvaluationFeatureAttributionOp\n",
    "\n",
    "from google_cloud_pipeline_components._implementation.model import GetVertexModelOp\n",
    "from google_cloud_pipeline_components._implementation.model_evaluation import (\n",
    "    ModelImportEvaluationOp, \n",
    "    TargetFieldDataRemoverOp, \n",
    "    EvaluationDataSamplerOp,\n",
    ")\n",
    "\n",
    "@dsl.pipeline(\n",
    "  name=PIPELINE_NAME\n",
    ")\n",
    "def pipeline(\n",
    "    vertex_project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    new_bq_dataset_name: str,\n",
    "    batch_predict_machine_type: str,\n",
    "    # gcs_root_dir: str,\n",
    "    target_column: str,\n",
    "    model_name: str,\n",
    "    new_bq_dataset: str,\n",
    "    batch_predict_instances_format: str,\n",
    "    prediction_dataset_bq_path: str,\n",
    "):\n",
    "    \"\"\"An eval pipeline.\"\"\"\n",
    "\n",
    "    # create BQ dataset\n",
    "    create_dataset_op = (\n",
    "      create_bq_dataset.create_bq_dataset(\n",
    "          project=vertex_project,\n",
    "          vertex_dataset=\"tmp\",\n",
    "          new_bq_dataset=new_bq_dataset_name,\n",
    "          bq_location=location\n",
    "      )\n",
    "    )\n",
    "    \n",
    "    get_model_task = GetVertexModelOp(model_name=model_name)\n",
    "\n",
    "    # ======================================\n",
    "    # Model Eval Workflow\n",
    "    # ======================================\n",
    "\n",
    "    # Run Data-sampling task\n",
    "    data_sampler_task = (\n",
    "        EvaluationDataSamplerOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            # root_dir=gcs_root_dir,\n",
    "            bigquery_source_uri=prediction_dataset_bq_path,\n",
    "            instances_format=batch_predict_instances_format,\n",
    "            sample_size=3000,\n",
    "            # dataflow_subnetwork=None,\n",
    "            dataflow_use_public_ips=True,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Run Target field-removal task\n",
    "    target_remover_task = (\n",
    "        TargetFieldDataRemoverOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            # root_dir=gcs_root_dir,\n",
    "            bigquery_source_uri=data_sampler_task.outputs[\"bigquery_output_table\"],\n",
    "            instances_format=batch_predict_instances_format,\n",
    "            target_field_name=target_column,\n",
    "            # dataflow_subnetwork=None,\n",
    "            dataflow_use_public_ips=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Run Batch Explanations\n",
    "    batch_predict_task = (\n",
    "        ModelBatchPredictOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            model=get_model_task.outputs['model'],\n",
    "            job_display_name=f\"bpj-{PIPELINE_NAME}\",\n",
    "            bigquery_source_input_uri=target_remover_task.outputs[\"bigquery_output_table\"],\n",
    "            instances_format=batch_predict_instances_format,\n",
    "            predictions_format=batch_predict_instances_format,\n",
    "            bigquery_destination_output_uri=create_dataset_op.outputs[\"bq_dataset_uri\"], \n",
    "            machine_type=batch_predict_machine_type,\n",
    "            starting_replica_count=4,\n",
    "            max_replica_count=12,\n",
    "            # Set the explanation parameters\n",
    "            generate_explanation=False,\n",
    "            # explanation_parameters=batch_predict_explanation_parameters,\n",
    "            # explanation_metadata=batch_predict_explanation_metadata,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Run evaluation based on prediction type and feature attribution component.\n",
    "    # After, import the model evaluations to the Vertex model.\n",
    "    model_eval_task = (\n",
    "        ModelEvaluationForecastingOp(\n",
    "            project=vertex_project,\n",
    "            location=location,\n",
    "            target_field_name=target_column,\n",
    "            predictions_bigquery_source=batch_predict_task.outputs[\"bigquery_output_table\"],\n",
    "            predictions_format=batch_predict_instances_format,\n",
    "            model=get_model_task.outputs['model'],\n",
    "            # prediction_score_column=\"prediction.scores\",\n",
    "            forecasting_type=\"quantile\", #\"point\",\n",
    "            forecasting_quantiles=[0.10, 0.25, 0.5, 0.75, .90],\n",
    "            ground_truth_bigquery_source=data_sampler_task.outputs[\"bigquery_output_table\"],\n",
    "            ground_truth_format=batch_predict_instances_format,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Import the evaluation results to the model resource\n",
    "    model_import_task = (\n",
    "        ModelImportEvaluationOp(\n",
    "            problem_type=\"forecasting\",\n",
    "            forecasting_metrics=model_eval_task.outputs[\"evaluation_metrics\"],\n",
    "            # feature_attributions=feature_attribution_task.outputs[\"feature_attributions\"],\n",
    "            model=get_model_task.outputs['model'],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "61fa69c0-9405-426a-aa49-81323864f210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIPELINE_JSON_SPEC_LOCAL = \"custom_pipeline_spec.json\"\n",
    "\n",
    "! rm -f $PIPELINE_JSON_SPEC_LOCAL\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, \n",
    "    package_path=PIPELINE_JSON_SPEC_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8dda4c4-6b0b-4aaf-a887-a184f193aa70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://custom_pipeline_spec.json [Content-Type=application/json]...\n",
      "/ [1 files][ 69.6 KiB/ 69.6 KiB]                                                \n",
      "Operation completed over 1 objects/69.6 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $PIPELINE_JSON_SPEC_LOCAL $EVAL_PIPE_DIR/$PIPELINE_JSON_SPEC_LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f2663282-5716-4d3c-bfe4-e23b265eacb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Some input parameters of the PipelineSpec.root are missing both defaultValue and default value from PipelineJob.runtimeConfig.parameter_values: ([new_bq_dataset])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:79\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/grpc/_channel.py:1160\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1154\u001b[0m (\n\u001b[1;32m   1155\u001b[0m     state,\n\u001b[1;32m   1156\u001b[0m     call,\n\u001b[1;32m   1157\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1158\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1159\u001b[0m )\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/grpc/_channel.py:1003\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Some input parameters of the PipelineSpec.root are missing both defaultValue and default value from PipelineJob.runtimeConfig.parameter_values: ([new_bq_dataset])\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.120.95:443 {grpc_message:\"Some input parameters of the PipelineSpec.root are missing both defaultValue and default value from PipelineJob.runtimeConfig.parameter_values: ([new_bq_dataset])\", grpc_status:3, created_time:\"2023-12-21T17:06:25.653798492+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m job \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mPipelineJob(\n\u001b[1;32m      2\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mPIPELINE_NAME,\n\u001b[1;32m      3\u001b[0m     template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEVAL_PIPE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPIPELINE_JSON_SPEC_LOCAL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     }   \n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVERTEX_SA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# network=f'projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}'\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:319\u001b[0m, in \u001b[0;36mPipelineJob.run\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run this configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m network \u001b[38;5;241m=\u001b[39m network \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mnetwork\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:817\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    816\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    820\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:350\u001b[0m, in \u001b[0;36mPipelineJob._run\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;129m@base\u001b[39m\u001b[38;5;241m.\u001b[39moptional_sync()\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m     create_request_timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to ensure network synchronization and to run\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    the configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m            Optional. The timeout for the create request in seconds.\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_block_until_complete()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform/pipeline_jobs.py:425\u001b[0m, in \u001b[0;36mPipelineJob.submit\u001b[0;34m(self, service_account, network, create_request_timeout, experiment)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_experiment(experiment)\n\u001b[1;32m    423\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_create_with_lro(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m--> 425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipeline_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline_job_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_create_complete_with_getter(\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m )\n\u001b[1;32m    436\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView Pipeline Job:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dashboard_uri())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/pipeline_service/client.py:1347\u001b[0m, in \u001b[0;36mPipelineServiceClient.create_pipeline_job\u001b[0;34m(self, request, parent, pipeline_job, pipeline_job_id, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   1343\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparent\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mparent),)),\n\u001b[1;32m   1344\u001b[0m )\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1347\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:81\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Some input parameters of the PipelineSpec.root are missing both defaultValue and default value from PipelineJob.runtimeConfig.parameter_values: ([new_bq_dataset])"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=f\"{EVAL_PIPE_DIR}/{PIPELINE_JSON_SPEC_LOCAL}\",\n",
    "    pipeline_root=EVAL_PIPE_DIR,\n",
    "    enable_caching=True,\n",
    "    failure_policy='fast', # slow | fast\n",
    "    parameter_values={\n",
    "        'vertex_project': PROJECT_ID,\n",
    "        'location': LOCATION,\n",
    "        'version': VERSION,\n",
    "        \"batch_predict_instances_format\": 'bigquery',\n",
    "        \"target_column\": target_column,\n",
    "        \"model_name\": BPJ_OUTPUT_DICT['model'],\n",
    "        \"batch_predict_machine_type\": \"n2-standard-4\",\n",
    "        # \"gcs_root_dir\": EVAL_PIPE_DIR,\n",
    "        # \"data_source_dataset\": f'forecast_eval_{VERSION}_us',\n",
    "        \"prediction_dataset_bq_path\" : PREDICTION_DATASET_BQ_PATH,\n",
    "        \"new_bq_dataset_name\" : f\"a_fresh_eval_{VERSION}_us\"\n",
    "    }   \n",
    ")\n",
    "\n",
    "job.run(\n",
    "    sync=True,\n",
    "    service_account=VERTEX_SA,\n",
    "    # network=f'projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5027f1f2-50cf-447e-85d4-6bcac75093e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bq://bigquery-public-data:iowa_liquor_sales_forecasting.2021_sales_predict'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTION_DATASET_BQ_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821840d9-c20d-4830-bfc5-f6c29b1752bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BQ dataset for source data source\n",
    "DATA_SOURCE_DATASET = f'forecast_eval_{VERSION}_us'\n",
    "\n",
    "bigquery_source_uri = PREDICTION_DATASET_BQ_PATH\n",
    "\n",
    "# 'bq://hybrid-vertex.forecast_refresh_v1'\n",
    "\n",
    "\"batch_predict_instances_format\": 'bigquery',\n",
    "\n",
    "parameter_values={\n",
    "    'vertex_project': PROJECT_ID,\n",
    "    'location': LOCATION,\n",
    "    'version': VERSION,\n",
    "    \"batch_predict_instances_format\": 'bigquery',\n",
    "    \"target_column\": target_column,\n",
    "    \"model_name\": BPJ_OUTPUT_DICT['model'],\n",
    "    \"batch_predict_machine_type\": \"n1-standard-4\",\n",
    "    \"gcs_root_dir\": XXXXXX,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724dade-07c2-45f2-8a1c-f4b650755a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997befdd-a2fd-4b65-a48a-2eb3a2113b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bd9c7-dd3a-4161-85d6-5703226cc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RUN_EVALUATION:\n",
    "#     forecast_EVALS = forecasting_mp_model.list_model_evaluations()\n",
    "    \n",
    "#     for model_evaluation in forecast_EVALS:\n",
    "#         pprint(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15bf095d-32f7-4987-af58-5e66d7618155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get evaluations\n",
    "model_evaluations = trained_forecast.list_model_evaluations()\n",
    "\n",
    "# Print the evaluation metrics\n",
    "for evaluation in model_evaluations:\n",
    "    evaluation = evaluation.to_dict()\n",
    "    print(\"Model's evaluation metrics from training:\\n\")\n",
    "    metrics = evaluation[\"metrics\"]\n",
    "    for metric in metrics.keys():\n",
    "        print(f\"metric: {metric}, value: {metrics[metric]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25696115-3ff1-45ac-897a-e149a3d7a649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qs_eval['date'] = qs_eval[\"date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "qs_eval['predicted_sales_mean'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c586e62-b65e-47cf-ae45-769b96d09ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the results as a dataframe\n",
    "# df_output = batch_prediction_job.iter_outputs(bq_max_results=1000).to_dataframe()\n",
    "\n",
    "# Convert the dates to the datetime64 datatype\n",
    "# df_output[\"date\"] = df_output[\"date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "# Extract the predicted sales and convert to floats\n",
    "# df_output[\"pred_median\"] = (\n",
    "#     df_output[\"predicted_sales\"].apply(lambda x: x[\"value\"]).astype(float)\n",
    "# )\n",
    "\n",
    "# df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32e0fe-90a1-4fc8-958a-3e73aa590998",
   "metadata": {},
   "source": [
    "### Compare predictions vs ground truth\n",
    "\n",
    "> TODO\n",
    "\n",
    "Plot the predicted values vs the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef62f44-2d5b-41f5-9b0d-a0eed0165047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a shared dataframe to plot predictions vs ground truth\n",
    "df_output[\"sales_comparison\"] = df_output[\"predicted_sales\"]\n",
    "df_output[\"is_ground_truth\"] = False\n",
    "df_test_horizon_actual[\"sales_comparison\"] = df_test_horizon_actual[\"sales\"]\n",
    "df_test_horizon_actual[\"is_ground_truth\"] = True\n",
    "df_prediction_comparison = pd.concat([df_output, df_test_horizon_actual])\n",
    "\n",
    "# Plot sales\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(24, 12)\n",
    "\n",
    "sns.relplot(\n",
    "    data=df_prediction_comparison,\n",
    "    x=\"date\",\n",
    "    y=\"sales_comparison\",\n",
    "    hue=\"product_at_store\",\n",
    "    style=\"store\",\n",
    "    row=\"is_ground_truth\",\n",
    "    height=5,\n",
    "    aspect=4,\n",
    "    kind=\"line\",\n",
    "    ci=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc865dea-382d-4dfc-bff0-5fc7d6f5a95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1deaf341-4781-45fc-b475-e9bc4111557a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91cbd6d-0839-47bb-bc2d-286de010919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_forecast = aiplatform.Model(\n",
    "#     model_name=BPJ_OUTPUT_DICT['model']\n",
    "# )\n",
    "# my_evaluation_job = trained_forecast.evaluate(\n",
    "#     prediction_type=\"classification\",\n",
    "#     target_field_name=\"type\",\n",
    "#     data_source_uris=[\"gs://sdk-model-eval/my-prediction-data.csv\"],\n",
    "#     staging_bucket=\"gs://my-staging-bucket/eval_pipeline_root\",\n",
    "# )\n",
    "# my_evaluation_job.wait()\n",
    "# my_evaluation = my_evaluation_job.get_model_evaluation()\n",
    "# my_evaluation.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc736d6-e6a0-4228-a063-33242a0ba53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from google_cloud_pipeline_components.aiplatform import ModelBatchPredictOp\n",
    "# from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "\n",
    "# from google_cloud_pipeline_components.v1.model_evaluation import ModelEvaluationForecastingOp\n",
    "\n",
    "# from google_cloud_pipeline_components.preview.model_evaluation import ModelEvaluationFeatureAttributionOp\n",
    "\n",
    "# from google_cloud_pipeline_components._implementation.model_evaluation import (ModelImportEvaluationOp, TargetFieldDataRemoverOp)\n",
    "\n",
    "# preview.model_evaluation.ModelEvaluationFeatureAttributionOp\n",
    "# from google_cloud_pipeline_components.experimental.evaluation import (\n",
    "#     # EvaluationDataSamplerOp, \n",
    "#     # GetVertexModelOp,\n",
    "#     # ModelEvaluationForecastingOp, \n",
    "#     # ModelEvaluationFeatureAttributionOp,\n",
    "#     # ModelImportEvaluationOp, \n",
    "#     # TargetFieldDataRemoverOp\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
